{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, precision_score,confusion_matrix, recall_score, roc_auc_score\n",
    "#for bayesian optimization\n",
    "#!pip install scikit-optimize\n",
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History</th>\n",
       "      <th>History_score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>6</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.75</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  SCORE_A  PARA_B  SCORE_B  TOTAL  numbers  \\\n",
       "0          3.89          23    4.18        6    2.50        2   6.68      5.0   \n",
       "1          3.89           6    0.00        2    4.83        2   4.83      5.0   \n",
       "2          3.89           6    0.51        2    0.23        2   0.74      5.0   \n",
       "3          3.89           6    0.00        2   10.80        6  10.80      6.0   \n",
       "4          3.89           6    0.00        2    0.08        2   0.08      5.0   \n",
       "\n",
       "   Marks  Money_Value  MONEY_Marks  District  Loss  LOSS_SCORE  History  \\\n",
       "0      2         3.38            2         2     0           2        0   \n",
       "1      2         0.94            2         2     0           2        0   \n",
       "2      2         0.00            2         2     0           2        0   \n",
       "3      6        11.75            6         2     0           2        0   \n",
       "4      2         0.00            2         2     0           2        0   \n",
       "\n",
       "   History_score  Score  Risk  \n",
       "0              2    2.4     1  \n",
       "1              2    2.0     0  \n",
       "2              2    2.0     0  \n",
       "3              2    4.4     1  \n",
       "4              2    2.0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/shadow23-cmi/Data-Driven-Prediction-of-Fraudulent-Firm/main/Data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"SCORE_A\",\"SCORE_B\",\"Marks\",\"MONEY_Marks\",\"LOSS_SCORE\",\"History_score\",\"Score\"]\n",
    "for column in to_drop:\n",
    "    data.drop(column,inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>History</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  PARA_B  TOTAL  numbers  Money_Value  \\\n",
       "0          3.89          23    4.18    2.50   6.68      5.0         3.38   \n",
       "1          3.89           6    0.00    4.83   4.83      5.0         0.94   \n",
       "2          3.89           6    0.51    0.23   0.74      5.0         0.00   \n",
       "3          3.89           6    0.00   10.80  10.80      6.0        11.75   \n",
       "4          3.89           6    0.00    0.08   0.08      5.0         0.00   \n",
       "\n",
       "   District  Loss  History  Risk  \n",
       "0         2     0        0     1  \n",
       "1         2     0        0     0  \n",
       "2         2     0        0     0  \n",
       "3         2     0        0     1  \n",
       "4         2     0        0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>History</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>55.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  PARA_B  TOTAL  numbers  Money_Value  \\\n",
       "642         55.57           4    0.23     0.0   0.23      5.0          NaN   \n",
       "\n",
       "     District  Loss  History  Risk  \n",
       "642         2     0        0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Money_Value.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-fcbcd43c364e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Money_Value\"][642]=0\n"
     ]
    }
   ],
   "source": [
    "data[\"Money_Value\"][642]=0\n",
    "#data[\"Money_Value\"].fillna((data[\"Money_Value\"].mode()),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>History</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  PARA_B  TOTAL  numbers  Money_Value  \\\n",
       "0          3.89          23    4.18    2.50   6.68      5.0         3.38   \n",
       "1          3.89           6    0.00    4.83   4.83      5.0         0.94   \n",
       "2          3.89           6    0.51    0.23   0.74      5.0         0.00   \n",
       "3          3.89           6    0.00   10.80  10.80      6.0        11.75   \n",
       "4          3.89           6    0.00    0.08   0.08      5.0         0.00   \n",
       "\n",
       "   District  Loss  History  Risk  \n",
       "0         2     0        0     1  \n",
       "1         2     0        0     0  \n",
       "2         2     0        0     0  \n",
       "3         2     0        0     1  \n",
       "4         2     0        0     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'41', '13', '16', '28', '8', '20', '15', '36', '1', '6', '23', 'SAFIDON', '5', '9', '25', '4', '31', '24', '44', '2', '18', '38', 'NUH', '27', '39', '17', '3', '42', '7', '35', '21', '22', '29', '14', '32', '34', '30', '43', '40', '12', '33', '19', '11', 'LOHARU', '37'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data.LOCATION_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45}\n"
     ]
    }
   ],
   "source": [
    "data=data.replace({\"LOHARU\":10,\n",
    "                   \"NUH\":26,\n",
    "                   \"SAFIDON\":45})\n",
    "data.LOCATION_ID=data.LOCATION_ID.astype(int)\n",
    "print(set(data.LOCATION_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature and target from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data[\"Risk\"].to_numpy()\n",
    "feature=data.drop([\"Risk\"],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "feature_scaled = pd.DataFrame(sc_X.fit_transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree=sklearn.tree.DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                                  max_depth=4,\n",
    "                                                  min_samples_leaf=25,\n",
    "                                                  class_weight={1:1,0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight={0: 1, 1: 1}, criterion='entropy',\n",
       "                       max_depth=4, min_samples_leaf=25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(239.14285714285714, 195.696, 'X[2] <= 0.985\\nentropy = 0.954\\nsamples = 620\\nvalue = [232, 388]'),\n",
       " Text(191.31428571428572, 152.208, 'X[7] <= 3.0\\nentropy = 0.875\\nsamples = 329\\nvalue = [232, 97]'),\n",
       " Text(143.4857142857143, 108.72, 'X[4] <= 1.805\\nentropy = 0.674\\nsamples = 282\\nvalue = [232, 50]'),\n",
       " Text(95.65714285714286, 65.232, 'X[6] <= 1.14\\nentropy = 0.347\\nsamples = 246\\nvalue = [230, 16]'),\n",
       " Text(47.82857142857143, 21.744, 'entropy = 0.159\\nsamples = 215\\nvalue = [210, 5]'),\n",
       " Text(143.4857142857143, 21.744, 'entropy = 0.938\\nsamples = 31\\nvalue = [20, 11]'),\n",
       " Text(191.31428571428572, 65.232, 'entropy = 0.31\\nsamples = 36\\nvalue = [2, 34]'),\n",
       " Text(239.14285714285714, 108.72, 'entropy = 0.0\\nsamples = 47\\nvalue = [0, 47]'),\n",
       " Text(286.9714285714286, 152.208, 'entropy = 0.0\\nsamples = 291\\nvalue = [0, 291]')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(decision_tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Decision Tree ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.94871795 1.         0.97435897 0.94871795 0.94871795 0.94871795\n",
      " 0.97435897 0.94871795 0.94736842 0.92105263] \n",
      " precision: [1.         0.975      0.97435897 1.         0.97368421 0.97368421\n",
      " 1.         1.         0.97297297 1.        ] \n",
      " accuracy: [0.96774194 0.98387097 0.96774194 0.96774194 0.9516129  0.9516129\n",
      " 0.98387097 0.96774194 0.9516129  0.9516129 ] \n",
      " fscore: [0.97368421 0.98734177 0.97435897 0.97368421 0.96103896 0.96103896\n",
      " 0.98701299 0.97368421 0.96       0.95890411] \n",
      "\n",
      "recall mean   : 0.9560728744939271 with starderd deviation: 0.0204230625547734\n",
      "precision mean: 0.986970036838458 with starderd deviation: 0.013039035766414919\n",
      "accuracy mean : 0.964516129032258 with starderd deviation: 0.012069862537980446\n",
      "fscore   mean : 0.9710748396769769 with starderd deviation: 0.010109728417538025\n"
     ]
    }
   ],
   "source": [
    "#CROSS-VALIDATION\n",
    "\n",
    "crs=cross_validate(decision_tree,\n",
    "                   X_train,\n",
    "                   y_train,\n",
    "                   cv=10,\n",
    "                   scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                   n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"\\nFor Decision Tree ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.933322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Cross Val Accuracy  Precision    Recall  F1 Score  \\\n",
       "0  decision_tree  0.929487            0.964516   0.967742  0.918367  0.942408   \n",
       "\n",
       "        ROC  \n",
       "0  0.933322  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_predict_r = decision_tree.predict(X_test)\n",
    "print(type(y_predict_r),type(y_test))\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['decision_tree',acc, crs[\"test_accuracy\"].mean(),prec,rec, f1,roc]],\n",
    "               columns = ['Model', 'Accuracy','Cross Val Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_criterion = Categorical(categories=['entropy', 'gini'],\n",
    "                             name='criterion')\n",
    "dim_max_depth = Integer(low=2, high=8, name=\"max_depth\")\n",
    "dim_min_samples_leaf = Integer(low=20, high= 50, name=\"min_samples_leaf\")\n",
    "dim_class_weight = Real(low=1.0, high= 2.0,name=\"class_weight\")\n",
    "\n",
    "dimensions=[dim_criterion,\n",
    "            dim_max_depth,\n",
    "            dim_min_samples_leaf,\n",
    "            dim_class_weight]\n",
    "\n",
    "default_parameters = [\"gini\", 4, 25, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(criterion,\n",
    "                max_depth,\n",
    "                min_samples_leaf,\n",
    "                class_weight):\n",
    "    decision_tree=sklearn.tree.DecisionTreeClassifier(criterion = criterion,\n",
    "                                                  max_depth = max_depth,\n",
    "                                                  min_samples_leaf = min_samples_leaf,\n",
    "                                                  class_weight={1:class_weight,0:1})\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(criterion,\n",
    "                max_depth,\n",
    "                min_samples_leaf,\n",
    "                class_weight):\n",
    "    model = create_model(criterion = criterion,\n",
    "                        max_depth = max_depth,\n",
    "                        min_samples_leaf = min_samples_leaf,\n",
    "                        class_weight = class_weight)\n",
    "    #model.fit(feature,target)\n",
    "    crs=cross_validate(model,\n",
    "                       feature_scaled,\n",
    "                       target,\n",
    "                       cv=10,\n",
    "                       scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                       n_jobs=2)\n",
    "    \n",
    "    print(\"recall mean   :\", round(crs[\"test_recall\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "    print(\"precision mean:\",round(crs[\"test_precision\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_precision\"].std(),3))\n",
    "    print(\"accuracy mean :\",round(crs[\"test_accuracy\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_accuracy\"].std(),3))\n",
    "    print(\"fscore   mean :\",round(crs[\"test_f1\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_f1\"].std(),3))\n",
    "    print(\"\\n\\n\")\n",
    "    return -(crs[\"test_accuracy\"].mean() * crs[\"test_recall\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.96 with starderd deviation: 0.062\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.038\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.036\n",
      "precision mean: 0.94 with starderd deviation: 0.072\n",
      "accuracy mean : 0.93 with starderd deviation: 0.059\n",
      "fscore   mean : 0.95 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.89 with starderd deviation: 0.113\n",
      "precision mean: 0.97 with starderd deviation: 0.07\n",
      "accuracy mean : 0.91 with starderd deviation: 0.081\n",
      "fscore   mean : 0.92 with starderd deviation: 0.071\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.036\n",
      "precision mean: 0.97 with starderd deviation: 0.067\n",
      "accuracy mean : 0.95 with starderd deviation: 0.06\n",
      "fscore   mean : 0.96 with starderd deviation: 0.044\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.88 with starderd deviation: 0.111\n",
      "precision mean: 0.92 with starderd deviation: 0.105\n",
      "accuracy mean : 0.86 with starderd deviation: 0.086\n",
      "fscore   mean : 0.89 with starderd deviation: 0.069\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.89 with starderd deviation: 0.113\n",
      "precision mean: 0.97 with starderd deviation: 0.07\n",
      "accuracy mean : 0.91 with starderd deviation: 0.081\n",
      "fscore   mean : 0.92 with starderd deviation: 0.071\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.89 with starderd deviation: 0.091\n",
      "precision mean: 0.85 with starderd deviation: 0.137\n",
      "accuracy mean : 0.81 with starderd deviation: 0.114\n",
      "fscore   mean : 0.86 with starderd deviation: 0.076\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.97 with starderd deviation: 0.036\n",
      "precision mean: 0.94 with starderd deviation: 0.063\n",
      "accuracy mean : 0.94 with starderd deviation: 0.054\n",
      "fscore   mean : 0.96 with starderd deviation: 0.04\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.93 with starderd deviation: 0.095\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.94 with starderd deviation: 0.075\n",
      "fscore   mean : 0.95 with starderd deviation: 0.065\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.93 with starderd deviation: 0.087\n",
      "precision mean: 0.97 with starderd deviation: 0.067\n",
      "accuracy mean : 0.93 with starderd deviation: 0.073\n",
      "fscore   mean : 0.95 with starderd deviation: 0.061\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.94 with starderd deviation: 0.04\n",
      "precision mean: 0.94 with starderd deviation: 0.084\n",
      "accuracy mean : 0.92 with starderd deviation: 0.068\n",
      "fscore   mean : 0.94 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.96 with starderd deviation: 0.062\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.96 with starderd deviation: 0.039\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.041\n",
      "precision mean: 0.97 with starderd deviation: 0.063\n",
      "accuracy mean : 0.95 with starderd deviation: 0.058\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.041\n",
      "precision mean: 0.96 with starderd deviation: 0.06\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.042\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.07\n",
      "accuracy mean : 0.95 with starderd deviation: 0.054\n",
      "fscore   mean : 0.96 with starderd deviation: 0.038\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.067\n",
      "accuracy mean : 0.95 with starderd deviation: 0.061\n",
      "fscore   mean : 0.96 with starderd deviation: 0.044\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.87 with starderd deviation: 0.108\n",
      "precision mean: 1.0 with starderd deviation: 0.007\n",
      "accuracy mean : 0.91 with starderd deviation: 0.067\n",
      "fscore   mean : 0.92 with starderd deviation: 0.066\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.94 with starderd deviation: 0.071\n",
      "precision mean: 0.94 with starderd deviation: 0.107\n",
      "accuracy mean : 0.92 with starderd deviation: 0.114\n",
      "fscore   mean : 0.94 with starderd deviation: 0.085\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.037\n",
      "precision mean: 0.94 with starderd deviation: 0.074\n",
      "accuracy mean : 0.93 with starderd deviation: 0.055\n",
      "fscore   mean : 0.95 with starderd deviation: 0.038\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.037\n",
      "precision mean: 0.95 with starderd deviation: 0.072\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.95 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.063\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.042\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.04\n",
      "precision mean: 0.95 with starderd deviation: 0.065\n",
      "accuracy mean : 0.94 with starderd deviation: 0.056\n",
      "fscore   mean : 0.96 with starderd deviation: 0.04\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.86 with starderd deviation: 0.112\n",
      "precision mean: 0.89 with starderd deviation: 0.098\n",
      "accuracy mean : 0.84 with starderd deviation: 0.078\n",
      "fscore   mean : 0.87 with starderd deviation: 0.065\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.89 with starderd deviation: 0.113\n",
      "precision mean: 0.93 with starderd deviation: 0.119\n",
      "accuracy mean : 0.88 with starderd deviation: 0.113\n",
      "fscore   mean : 0.9 with starderd deviation: 0.084\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.87 with starderd deviation: 0.118\n",
      "precision mean: 0.89 with starderd deviation: 0.098\n",
      "accuracy mean : 0.84 with starderd deviation: 0.083\n",
      "fscore   mean : 0.87 with starderd deviation: 0.069\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.034\n",
      "precision mean: 0.95 with starderd deviation: 0.066\n",
      "accuracy mean : 0.95 with starderd deviation: 0.05\n",
      "fscore   mean : 0.96 with starderd deviation: 0.034\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.033\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.051\n",
      "fscore   mean : 0.96 with starderd deviation: 0.035\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.96 with starderd deviation: 0.066\n",
      "accuracy mean : 0.94 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.041\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.97 with starderd deviation: 0.037\n",
      "precision mean: 0.95 with starderd deviation: 0.064\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.041\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.98 with starderd deviation: 0.033\n",
      "precision mean: 0.94 with starderd deviation: 0.069\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.035\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.85 with starderd deviation: 0.119\n",
      "precision mean: 0.97 with starderd deviation: 0.069\n",
      "accuracy mean : 0.88 with starderd deviation: 0.077\n",
      "fscore   mean : 0.9 with starderd deviation: 0.071\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.043\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.04\n",
      "precision mean: 0.96 with starderd deviation: 0.06\n",
      "accuracy mean : 0.95 with starderd deviation: 0.055\n",
      "fscore   mean : 0.96 with starderd deviation: 0.04\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.062\n",
      "accuracy mean : 0.95 with starderd deviation: 0.054\n",
      "fscore   mean : 0.96 with starderd deviation: 0.04\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.98 with starderd deviation: 0.038\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.052\n",
      "fscore   mean : 0.96 with starderd deviation: 0.036\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.04\n",
      "precision mean: 0.97 with starderd deviation: 0.066\n",
      "accuracy mean : 0.95 with starderd deviation: 0.06\n",
      "fscore   mean : 0.96 with starderd deviation: 0.044\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.89 with starderd deviation: 0.113\n",
      "precision mean: 0.93 with starderd deviation: 0.119\n",
      "accuracy mean : 0.88 with starderd deviation: 0.113\n",
      "fscore   mean : 0.9 with starderd deviation: 0.084\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.04\n",
      "precision mean: 0.96 with starderd deviation: 0.06\n",
      "accuracy mean : 0.95 with starderd deviation: 0.055\n",
      "fscore   mean : 0.96 with starderd deviation: 0.04\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.041\n",
      "precision mean: 0.96 with starderd deviation: 0.06\n",
      "accuracy mean : 0.95 with starderd deviation: 0.057\n",
      "fscore   mean : 0.96 with starderd deviation: 0.042\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.98 with starderd deviation: 0.033\n",
      "precision mean: 0.94 with starderd deviation: 0.068\n",
      "accuracy mean : 0.94 with starderd deviation: 0.051\n",
      "fscore   mean : 0.96 with starderd deviation: 0.035\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.94 with starderd deviation: 0.071\n",
      "precision mean: 0.93 with starderd deviation: 0.104\n",
      "accuracy mean : 0.91 with starderd deviation: 0.111\n",
      "fscore   mean : 0.93 with starderd deviation: 0.083\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp_result = gp_minimize(func=fitness,\n",
    "                        dimensions=dimensions,\n",
    "                        n_calls=50,\n",
    "                        n_jobs=2,\n",
    "                        x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entropy', 8, 20, 1.702467131718288]\n"
     ]
    }
   ],
   "source": [
    "print(gp_result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Decision Tree ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [1.         0.94736842 0.94871795 0.97435897 0.97435897 1.\n",
      " 1.         1.         1.         1.        ] \n",
      " precision: [0.95       0.94736842 0.925      0.95       0.9047619  0.975\n",
      " 0.95121951 0.95121951 0.95121951 0.95121951] \n",
      " accuracy: [0.96774194 0.93548387 0.91935484 0.9516129  0.91935484 0.98387097\n",
      " 0.96774194 0.96774194 0.96774194 0.96774194] \n",
      " fscore: [0.97435897 0.94736842 0.93670886 0.96202532 0.9382716  0.98734177\n",
      " 0.975      0.975      0.975      0.975     ] \n",
      "\n",
      "recall mean   : 0.9844804318488528 with starderd deviation: 0.020751593485933785\n",
      "precision mean: 0.9457008374595024 with starderd deviation: 0.017676343861237905\n",
      "accuracy mean : 0.9548387096774196 with starderd deviation: 0.02139757929261551\n",
      "fscore   mean : 0.9646074949716965 with starderd deviation: 0.016792026567494598\n"
     ]
    }
   ],
   "source": [
    "model = create_model(gp_result.x[0],gp_result.x[1],gp_result.x[2],gp_result.x[3])\n",
    "#fit=model.fit(X_train,y_train)\n",
    "#CROSS-VALIDATION\n",
    "\n",
    "crs=cross_validate(model,\n",
    "                   X_train,\n",
    "                   y_train,\n",
    "                   cv=10,\n",
    "                   scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                   n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"\\nFor Decision Tree ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.98448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Cross Val Accuracy  Accuracy  Cross val FRecall  Recall  \\\n",
       "0  decision_tree            0.954839  0.967949            0.98448     1.0   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.975124  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_predict_r = model.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "results = pd.DataFrame([['decision_tree', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(231.7846153846154, 203.85, 'X[2] <= 0.97\\nentropy = 0.827\\nsamples = 620\\nvalue = [232.0, 660.557]'),\n",
       " Text(180.27692307692308, 176.67000000000002, 'X[7] <= 3.0\\nentropy = 0.978\\nsamples = 328\\nvalue = [232.0, 163.437]'),\n",
       " Text(154.52307692307693, 149.49, 'X[3] <= 1.05\\nentropy = 0.861\\nsamples = 286\\nvalue = [232.0, 91.933]'),\n",
       " Text(103.01538461538462, 122.31, 'X[6] <= 1.83\\nentropy = 0.526\\nsamples = 245\\nvalue = [227.0, 30.644]'),\n",
       " Text(77.26153846153846, 95.13, 'X[4] <= 1.265\\nentropy = 0.265\\nsamples = 223\\nvalue = [217.0, 10.215]'),\n",
       " Text(51.50769230769231, 67.94999999999999, 'X[1] <= 4.5\\nentropy = 0.168\\nsamples = 203\\nvalue = [200.0, 5.107]'),\n",
       " Text(25.753846153846155, 40.77000000000001, 'entropy = 0.615\\nsamples = 21\\nvalue = [19.0, 3.405]'),\n",
       " Text(77.26153846153846, 40.77000000000001, 'X[1] <= 30.5\\nentropy = 0.076\\nsamples = 182\\nvalue = [181.0, 1.702]'),\n",
       " Text(51.50769230769231, 13.590000000000003, 'entropy = 0.0\\nsamples = 162\\nvalue = [162, 0]'),\n",
       " Text(103.01538461538462, 13.590000000000003, 'entropy = 0.41\\nsamples = 20\\nvalue = [19.0, 1.702]'),\n",
       " Text(103.01538461538462, 67.94999999999999, 'entropy = 0.78\\nsamples = 20\\nvalue = [17.0, 5.107]'),\n",
       " Text(128.76923076923077, 95.13, 'entropy = 0.914\\nsamples = 22\\nvalue = [10.0, 20.43]'),\n",
       " Text(206.03076923076924, 122.31, 'X[2] <= 0.01\\nentropy = 0.386\\nsamples = 41\\nvalue = [5.0, 61.289]'),\n",
       " Text(180.27692307692308, 95.13, 'entropy = 0.533\\nsamples = 21\\nvalue = [4.0, 28.942]'),\n",
       " Text(231.7846153846154, 95.13, 'entropy = 0.194\\nsamples = 20\\nvalue = [1.0, 32.347]'),\n",
       " Text(206.03076923076924, 149.49, 'entropy = -0.0\\nsamples = 42\\nvalue = [0.0, 71.504]'),\n",
       " Text(283.2923076923077, 176.67000000000002, 'X[9] <= 0.5\\nentropy = 0.0\\nsamples = 292\\nvalue = [0.0, 497.12]'),\n",
       " Text(257.53846153846155, 149.49, 'entropy = 0.0\\nsamples = 260\\nvalue = [0.0, 442.641]'),\n",
       " Text(309.04615384615386, 149.49, 'entropy = 0.0\\nsamples = 32\\nvalue = [0.0, 54.479]')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "\n",
    "tree.plot_tree(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_kernel = Categorical(categories=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                             name='kernel')\n",
    "dim_degree = Integer(low=1, high=5, name=\"degree\")\n",
    "\n",
    "dim_class_weight = Real(low=1.0, high= 2.0,name=\"class_weight\")\n",
    "\n",
    "dimensions=[dim_kernel,\n",
    "            dim_degree,\n",
    "            dim_class_weight]\n",
    "\n",
    "default_parameters = [\"rbf\", 2, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(kernel,\n",
    "                degree,\n",
    "                class_weight):\n",
    "    svc=sklearn.svm.SVC(kernel=kernel,\n",
    "                        degree=degree,\n",
    "                        class_weight={1:class_weight,0:1})\n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(kernel,\n",
    "            degree,\n",
    "            class_weight):\n",
    "    model = create_model(kernel = kernel,\n",
    "                        degree = degree,\n",
    "                        class_weight = class_weight)\n",
    "    #model.fit(feature,target)\n",
    "    crs=cross_validate(model,\n",
    "                       feature,\n",
    "                       target,\n",
    "                       cv=10,\n",
    "                       scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                       n_jobs=2)\n",
    "    \n",
    "    print(\"recall mean   :\", round(crs[\"test_recall\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "    print(\"precision mean:\",round(crs[\"test_precision\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_precision\"].std(),3))\n",
    "    print(\"accuracy mean :\",round(crs[\"test_accuracy\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_accuracy\"].std(),3))\n",
    "    print(\"fscore   mean :\",round(crs[\"test_f1\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_f1\"].std(),3))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    return -(crs[\"test_accuracy\"].mean() * crs[\"test_recall\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.81 with starderd deviation: 0.379\n",
      "precision mean: 0.83 with starderd deviation: 0.173\n",
      "accuracy mean : 0.72 with starderd deviation: 0.215\n",
      "fscore   mean : 0.72 with starderd deviation: 0.324\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.099\n",
      "precision mean: 0.94 with starderd deviation: 0.044\n",
      "accuracy mean : 0.94 with starderd deviation: 0.055\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.099\n",
      "precision mean: 0.94 with starderd deviation: 0.044\n",
      "accuracy mean : 0.94 with starderd deviation: 0.055\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.096\n",
      "precision mean: 0.96 with starderd deviation: 0.035\n",
      "accuracy mean : 0.94 with starderd deviation: 0.054\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.81 with starderd deviation: 0.379\n",
      "precision mean: 0.83 with starderd deviation: 0.172\n",
      "accuracy mean : 0.72 with starderd deviation: 0.216\n",
      "fscore   mean : 0.72 with starderd deviation: 0.325\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.81 with starderd deviation: 0.375\n",
      "precision mean: 0.82 with starderd deviation: 0.182\n",
      "accuracy mean : 0.7 with starderd deviation: 0.213\n",
      "fscore   mean : 0.71 with starderd deviation: 0.315\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.82 with starderd deviation: 0.368\n",
      "precision mean: 0.81 with starderd deviation: 0.186\n",
      "accuracy mean : 0.7 with starderd deviation: 0.211\n",
      "fscore   mean : 0.72 with starderd deviation: 0.304\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.81 with starderd deviation: 0.379\n",
      "precision mean: 0.84 with starderd deviation: 0.171\n",
      "accuracy mean : 0.73 with starderd deviation: 0.219\n",
      "fscore   mean : 0.72 with starderd deviation: 0.327\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 1.0 with starderd deviation: 0.0\n",
      "precision mean: 0.63 with starderd deviation: 0.002\n",
      "accuracy mean : 0.63 with starderd deviation: 0.002\n",
      "fscore   mean : 0.77 with starderd deviation: 0.002\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.096\n",
      "precision mean: 0.96 with starderd deviation: 0.033\n",
      "accuracy mean : 0.94 with starderd deviation: 0.054\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.82 with starderd deviation: 0.368\n",
      "precision mean: 0.82 with starderd deviation: 0.184\n",
      "accuracy mean : 0.7 with starderd deviation: 0.21\n",
      "fscore   mean : 0.72 with starderd deviation: 0.305\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.93 with starderd deviation: 0.104\n",
      "precision mean: 0.97 with starderd deviation: 0.03\n",
      "accuracy mean : 0.94 with starderd deviation: 0.059\n",
      "fscore   mean : 0.94 with starderd deviation: 0.06\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.1\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.056\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.95 with starderd deviation: 0.098\n",
      "precision mean: 0.95 with starderd deviation: 0.04\n",
      "accuracy mean : 0.94 with starderd deviation: 0.054\n",
      "fscore   mean : 0.95 with starderd deviation: 0.052\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.96 with starderd deviation: 0.1\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.056\n",
      "fscore   mean : 0.95 with starderd deviation: 0.053\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.82 with starderd deviation: 0.368\n",
      "precision mean: 0.7 with starderd deviation: 0.149\n",
      "accuracy mean : 0.59 with starderd deviation: 0.081\n",
      "fscore   mean : 0.65 with starderd deviation: 0.254\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.82 with starderd deviation: 0.368\n",
      "precision mean: 0.7 with starderd deviation: 0.149\n",
      "accuracy mean : 0.59 with starderd deviation: 0.081\n",
      "fscore   mean : 0.65 with starderd deviation: 0.254\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.94 with starderd deviation: 0.096\n",
      "precision mean: 0.96 with starderd deviation: 0.033\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.052\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n",
      "recall mean   : 0.93 with starderd deviation: 0.104\n",
      "precision mean: 0.97 with starderd deviation: 0.03\n",
      "accuracy mean : 0.94 with starderd deviation: 0.059\n",
      "fscore   mean : 0.94 with starderd deviation: 0.06\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.93 with starderd deviation: 0.104\n",
      "precision mean: 0.97 with starderd deviation: 0.03\n",
      "accuracy mean : 0.94 with starderd deviation: 0.059\n",
      "fscore   mean : 0.94 with starderd deviation: 0.06\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall mean   : 0.96 with starderd deviation: 0.094\n",
      "precision mean: 0.94 with starderd deviation: 0.046\n",
      "accuracy mean : 0.94 with starderd deviation: 0.053\n",
      "fscore   mean : 0.95 with starderd deviation: 0.049\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp_result = gp_minimize(func=fitness,\n",
    "                        dimensions=dimensions,\n",
    "                        n_calls=50,\n",
    "                        n_jobs=2,\n",
    "                        x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear', 5, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(gp_result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For SVM ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.94871795 1.         0.97435897 1.         1.         0.97435897\n",
      " 1.         0.8974359  0.97435897 1.        ] \n",
      " precision: [0.90243902 0.92857143 0.92682927 0.95121951 0.95121951 0.97435897\n",
      " 0.95121951 0.97222222 0.92682927 0.95121951] \n",
      " accuracy: [0.90322581 0.9516129  0.93548387 0.96774194 0.96774194 0.96774194\n",
      " 0.96774194 0.91935484 0.93548387 0.96774194] \n",
      " fscore: [0.925      0.96296296 0.95       0.975      0.975      0.97435897\n",
      " 0.975      0.93333333 0.95       0.975     ] \n",
      "\n",
      "recall mean   : 0.976923076923077 with starderd deviation: 0.03129886055316334\n",
      "precision mean: 0.9436128234908724 with starderd deviation: 0.021166414634580417\n",
      "accuracy mean : 0.9483870967741936 with starderd deviation: 0.022580645161290352\n",
      "fscore   mean : 0.959565527065527 with starderd deviation: 0.018025489557747906\n"
     ]
    }
   ],
   "source": [
    "model = create_model(gp_result.x[0],gp_result.x[1],gp_result.x[2])\n",
    "#fit=model.fit(X_train,y_train)\n",
    "#CROSS-VALIDATION\n",
    "\n",
    "crs=cross_validate(model,\n",
    "                   X_train,\n",
    "                   y_train,\n",
    "                   cv=10,\n",
    "                   scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                   n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"\\nFor SVM ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Cross Val Accuracy  Accuracy  Cross val FRecall    Recall  \\\n",
       "0  decision_tree            0.954839  0.967949           0.984480  1.000000   \n",
       "1            SVM            0.948387  0.929487           0.976923  0.989583   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.975124  \n",
       "1  0.945274  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_predict_r = model.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['SVM', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting  Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B Need to set up tenserflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense , Flatten, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.3590 - accuracy: 0.5988 - val_loss: 0.8575 - val_accuracy: 0.7097\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.6855 - val_loss: 0.6514 - val_accuracy: 0.7742\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.8044 - val_loss: 0.6691 - val_accuracy: 0.7742\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8145 - val_loss: 0.4359 - val_accuracy: 0.8226\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8448 - val_loss: 0.3819 - val_accuracy: 0.8387\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8569 - val_loss: 0.3836 - val_accuracy: 0.8468\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8770 - val_loss: 0.3435 - val_accuracy: 0.8468\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8871 - val_loss: 0.3149 - val_accuracy: 0.8790\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.8931 - val_loss: 0.3176 - val_accuracy: 0.8629\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2963 - accuracy: 0.8891 - val_loss: 0.3077 - val_accuracy: 0.8710\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.8992 - val_loss: 0.2933 - val_accuracy: 0.8871\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.8931 - val_loss: 0.2934 - val_accuracy: 0.8790\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8891 - val_loss: 0.2842 - val_accuracy: 0.8790\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.8972 - val_loss: 0.2738 - val_accuracy: 0.9032\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2615 - accuracy: 0.8931 - val_loss: 0.2781 - val_accuracy: 0.8710\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2540 - accuracy: 0.8931 - val_loss: 0.2616 - val_accuracy: 0.9113\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.8911 - val_loss: 0.2619 - val_accuracy: 0.8871\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.8931 - val_loss: 0.2543 - val_accuracy: 0.8952\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2437 - accuracy: 0.8992 - val_loss: 0.2511 - val_accuracy: 0.8790\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.8911 - val_loss: 0.2531 - val_accuracy: 0.8871\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9052 - val_loss: 0.2394 - val_accuracy: 0.8952\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2245 - accuracy: 0.9052 - val_loss: 0.2398 - val_accuracy: 0.8952\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.8992 - val_loss: 0.2298 - val_accuracy: 0.9113\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9194 - val_loss: 0.2277 - val_accuracy: 0.9032\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2139 - accuracy: 0.8972 - val_loss: 0.2274 - val_accuracy: 0.9113\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2073 - accuracy: 0.9194 - val_loss: 0.2183 - val_accuracy: 0.9032\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2077 - accuracy: 0.8952 - val_loss: 0.2105 - val_accuracy: 0.9194\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9214 - val_loss: 0.2368 - val_accuracy: 0.8790\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1996 - accuracy: 0.9032 - val_loss: 0.1969 - val_accuracy: 0.9355\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1953 - accuracy: 0.9153 - val_loss: 0.2250 - val_accuracy: 0.8952\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9294 - val_loss: 0.2058 - val_accuracy: 0.9194\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9254 - val_loss: 0.2035 - val_accuracy: 0.9194\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.9395 - val_loss: 0.2101 - val_accuracy: 0.9113\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9234 - val_loss: 0.1861 - val_accuracy: 0.9355\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.9335 - val_loss: 0.2061 - val_accuracy: 0.9113\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9355 - val_loss: 0.1836 - val_accuracy: 0.9194\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1708 - accuracy: 0.9274 - val_loss: 0.1815 - val_accuracy: 0.9435\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.9496 - val_loss: 0.2130 - val_accuracy: 0.9113\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9234 - val_loss: 0.1734 - val_accuracy: 0.9355\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9435 - val_loss: 0.2027 - val_accuracy: 0.9113\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9415 - val_loss: 0.1695 - val_accuracy: 0.9355\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9435 - val_loss: 0.2001 - val_accuracy: 0.9113\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1482 - accuracy: 0.9435 - val_loss: 0.1654 - val_accuracy: 0.9355\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9496 - val_loss: 0.1849 - val_accuracy: 0.9113\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.9456 - val_loss: 0.1648 - val_accuracy: 0.9355\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1416 - accuracy: 0.9516 - val_loss: 0.1997 - val_accuracy: 0.9113\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.9395 - val_loss: 0.1559 - val_accuracy: 0.9435\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1364 - accuracy: 0.9476 - val_loss: 0.1779 - val_accuracy: 0.9194\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1349 - accuracy: 0.9476 - val_loss: 0.1689 - val_accuracy: 0.9194\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.9335 - val_loss: 0.1562 - val_accuracy: 0.9435\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1355 - accuracy: 0.9496 - val_loss: 0.1874 - val_accuracy: 0.9113\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9415 - val_loss: 0.1538 - val_accuracy: 0.9435\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9597 - val_loss: 0.1672 - val_accuracy: 0.9194\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.9536 - val_loss: 0.1553 - val_accuracy: 0.9435\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.9556 - val_loss: 0.1698 - val_accuracy: 0.9194\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9536 - val_loss: 0.1696 - val_accuracy: 0.9194\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 0.9456 - val_loss: 0.1514 - val_accuracy: 0.9435\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1168 - accuracy: 0.9516 - val_loss: 0.1962 - val_accuracy: 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9415 - val_loss: 0.1447 - val_accuracy: 0.9435\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1156 - accuracy: 0.9577 - val_loss: 0.1673 - val_accuracy: 0.9194\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9577 - val_loss: 0.1590 - val_accuracy: 0.9435\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9516 - val_loss: 0.1670 - val_accuracy: 0.9194\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9577 - val_loss: 0.1486 - val_accuracy: 0.9435\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9556 - val_loss: 0.1459 - val_accuracy: 0.9435\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9536 - val_loss: 0.1793 - val_accuracy: 0.9113\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9516 - val_loss: 0.1463 - val_accuracy: 0.9435\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9496 - val_loss: 0.1492 - val_accuracy: 0.9435\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9577 - val_loss: 0.1714 - val_accuracy: 0.9194\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9577 - val_loss: 0.1468 - val_accuracy: 0.9435\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9536 - val_loss: 0.1418 - val_accuracy: 0.9435\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9536 - val_loss: 0.1488 - val_accuracy: 0.9435\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.9536 - val_loss: 0.1786 - val_accuracy: 0.9113\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9597 - val_loss: 0.1419 - val_accuracy: 0.9435\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9556 - val_loss: 0.1707 - val_accuracy: 0.9194\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9556 - val_loss: 0.1436 - val_accuracy: 0.9435\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9597 - val_loss: 0.1728 - val_accuracy: 0.9194\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9536 - val_loss: 0.1360 - val_accuracy: 0.9435\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.9536 - val_loss: 0.1593 - val_accuracy: 0.9435\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9597 - val_loss: 0.1705 - val_accuracy: 0.9274\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9516 - val_loss: 0.1431 - val_accuracy: 0.9435\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9597 - val_loss: 0.1488 - val_accuracy: 0.9435\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9617 - val_loss: 0.1594 - val_accuracy: 0.9435\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9536 - val_loss: 0.1297 - val_accuracy: 0.9516\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9556 - val_loss: 0.1893 - val_accuracy: 0.9113\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9496 - val_loss: 0.1414 - val_accuracy: 0.9355\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9617 - val_loss: 0.1436 - val_accuracy: 0.9435\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9577 - val_loss: 0.1687 - val_accuracy: 0.9274\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9577 - val_loss: 0.1587 - val_accuracy: 0.9435\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9597 - val_loss: 0.1503 - val_accuracy: 0.9435\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9657 - val_loss: 0.1488 - val_accuracy: 0.9435\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0901 - accuracy: 0.9577 - val_loss: 0.1495 - val_accuracy: 0.9435\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9657 - val_loss: 0.1420 - val_accuracy: 0.9516\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0896 - accuracy: 0.9597 - val_loss: 0.1568 - val_accuracy: 0.9435\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0889 - accuracy: 0.9577 - val_loss: 0.1350 - val_accuracy: 0.9516\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9657 - val_loss: 0.1947 - val_accuracy: 0.9113\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9556 - val_loss: 0.1422 - val_accuracy: 0.9435\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9556 - val_loss: 0.1706 - val_accuracy: 0.9274\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0928 - accuracy: 0.9556 - val_loss: 0.1431 - val_accuracy: 0.9435\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9577 - val_loss: 0.1569 - val_accuracy: 0.9435\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9617 - val_loss: 0.1337 - val_accuracy: 0.9516\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9597 - val_loss: 0.1710 - val_accuracy: 0.9274\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9617 - val_loss: 0.1549 - val_accuracy: 0.9435\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9496 - val_loss: 0.1325 - val_accuracy: 0.9516\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9597 - val_loss: 0.1542 - val_accuracy: 0.9435\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9657 - val_loss: 0.1485 - val_accuracy: 0.9435\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9657 - val_loss: 0.1365 - val_accuracy: 0.9516\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9637 - val_loss: 0.1544 - val_accuracy: 0.9435\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9617 - val_loss: 0.1630 - val_accuracy: 0.9435\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9677 - val_loss: 0.1342 - val_accuracy: 0.9516\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9657 - val_loss: 0.1665 - val_accuracy: 0.9435\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9617 - val_loss: 0.1360 - val_accuracy: 0.9516\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9657 - val_loss: 0.1649 - val_accuracy: 0.9435\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9597 - val_loss: 0.1389 - val_accuracy: 0.9516\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9698 - val_loss: 0.1523 - val_accuracy: 0.9355\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9677 - val_loss: 0.1448 - val_accuracy: 0.9516\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9637 - val_loss: 0.1458 - val_accuracy: 0.9516\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9657 - val_loss: 0.1867 - val_accuracy: 0.9113\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9536 - val_loss: 0.1251 - val_accuracy: 0.9516\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9698 - val_loss: 0.1787 - val_accuracy: 0.9274\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9637 - val_loss: 0.1470 - val_accuracy: 0.9435\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9677 - val_loss: 0.1652 - val_accuracy: 0.9355\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9617 - val_loss: 0.1298 - val_accuracy: 0.9516\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9657 - val_loss: 0.1767 - val_accuracy: 0.9274\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9677 - val_loss: 0.1385 - val_accuracy: 0.9435\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9637 - val_loss: 0.1663 - val_accuracy: 0.9435\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9577 - val_loss: 0.1307 - val_accuracy: 0.9516\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.1680 - val_accuracy: 0.9355\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9657 - val_loss: 0.1332 - val_accuracy: 0.9516\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9617 - val_loss: 0.1554 - val_accuracy: 0.9435\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9698 - val_loss: 0.1377 - val_accuracy: 0.9597\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9577 - val_loss: 0.1506 - val_accuracy: 0.9516\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9677 - val_loss: 0.1476 - val_accuracy: 0.9516\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9637 - val_loss: 0.1478 - val_accuracy: 0.9516\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9637 - val_loss: 0.1421 - val_accuracy: 0.9597\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9657 - val_loss: 0.1372 - val_accuracy: 0.9597\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9677 - val_loss: 0.1518 - val_accuracy: 0.9516\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9637 - val_loss: 0.1439 - val_accuracy: 0.9516\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9617 - val_loss: 0.1784 - val_accuracy: 0.9274\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9577 - val_loss: 0.1319 - val_accuracy: 0.9435\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9657 - val_loss: 0.1544 - val_accuracy: 0.9435\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9597 - val_loss: 0.1456 - val_accuracy: 0.9355\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9698 - val_loss: 0.1624 - val_accuracy: 0.9435\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9677 - val_loss: 0.1401 - val_accuracy: 0.9597\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9698 - val_loss: 0.1399 - val_accuracy: 0.9516\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9718 - val_loss: 0.1416 - val_accuracy: 0.9435\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9637 - val_loss: 0.1639 - val_accuracy: 0.9435\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9698 - val_loss: 0.1394 - val_accuracy: 0.9355\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9617 - val_loss: 0.1667 - val_accuracy: 0.9435\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9677 - val_loss: 0.1392 - val_accuracy: 0.9435\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9637 - val_loss: 0.1488 - val_accuracy: 0.9516\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9615\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4000 - accuracy: 0.6331 - val_loss: 0.6359 - val_accuracy: 0.6129\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7157 - val_loss: 0.4791 - val_accuracy: 0.7500\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7319 - val_loss: 0.3997 - val_accuracy: 0.8065\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7480 - val_loss: 0.4264 - val_accuracy: 0.7823\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7762 - val_loss: 0.3679 - val_accuracy: 0.8145\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7641 - val_loss: 0.3508 - val_accuracy: 0.7984\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7823 - val_loss: 0.3631 - val_accuracy: 0.8629\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.7984 - val_loss: 0.3223 - val_accuracy: 0.8065\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8105 - val_loss: 0.3275 - val_accuracy: 0.8629\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8468 - val_loss: 0.3098 - val_accuracy: 0.8629\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8367 - val_loss: 0.2968 - val_accuracy: 0.8710\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8448 - val_loss: 0.2833 - val_accuracy: 0.8710\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8528 - val_loss: 0.2721 - val_accuracy: 0.8952\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8669 - val_loss: 0.2611 - val_accuracy: 0.8871\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8548 - val_loss: 0.2535 - val_accuracy: 0.8952\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8710 - val_loss: 0.2432 - val_accuracy: 0.9113\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8911 - val_loss: 0.2229 - val_accuracy: 0.9194\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8810 - val_loss: 0.2387 - val_accuracy: 0.9355\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8669 - val_loss: 0.2130 - val_accuracy: 0.9194\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8629 - val_loss: 0.2032 - val_accuracy: 0.9274\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8810 - val_loss: 0.2027 - val_accuracy: 0.9274\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8851 - val_loss: 0.1950 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.8770 - val_loss: 0.1925 - val_accuracy: 0.9516\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8911 - val_loss: 0.1858 - val_accuracy: 0.9194\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.8810 - val_loss: 0.1782 - val_accuracy: 0.9113\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.9093 - val_loss: 0.1782 - val_accuracy: 0.9516\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9012 - val_loss: 0.1687 - val_accuracy: 0.9194\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9133 - val_loss: 0.1823 - val_accuracy: 0.9516\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9133 - val_loss: 0.1581 - val_accuracy: 0.9274\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9173 - val_loss: 0.1610 - val_accuracy: 0.9516\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2159 - accuracy: 0.9194 - val_loss: 0.1610 - val_accuracy: 0.9516\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9194 - val_loss: 0.1520 - val_accuracy: 0.9435\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9254 - val_loss: 0.1557 - val_accuracy: 0.9597\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2026 - accuracy: 0.9194 - val_loss: 0.1405 - val_accuracy: 0.9516\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9294 - val_loss: 0.1467 - val_accuracy: 0.9516\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9335 - val_loss: 0.1329 - val_accuracy: 0.9516\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9294 - val_loss: 0.1532 - val_accuracy: 0.9516\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9315 - val_loss: 0.1278 - val_accuracy: 0.9274\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9335 - val_loss: 0.1270 - val_accuracy: 0.9516\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9254 - val_loss: 0.1613 - val_accuracy: 0.9435\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9335 - val_loss: 0.1254 - val_accuracy: 0.9516\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9294 - val_loss: 0.1329 - val_accuracy: 0.9516\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9375 - val_loss: 0.1252 - val_accuracy: 0.9516\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9415 - val_loss: 0.1152 - val_accuracy: 0.9597\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.9375 - val_loss: 0.1376 - val_accuracy: 0.9516\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9375 - val_loss: 0.1138 - val_accuracy: 0.9516\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9456 - val_loss: 0.1176 - val_accuracy: 0.9516\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9435 - val_loss: 0.1180 - val_accuracy: 0.9435\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9415 - val_loss: 0.1133 - val_accuracy: 0.9516\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9516 - val_loss: 0.1055 - val_accuracy: 0.9597\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9456 - val_loss: 0.1337 - val_accuracy: 0.9355\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.9415 - val_loss: 0.1025 - val_accuracy: 0.9677\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9456 - val_loss: 0.1280 - val_accuracy: 0.9355\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9395 - val_loss: 0.1067 - val_accuracy: 0.9516\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9456 - val_loss: 0.1021 - val_accuracy: 0.9597\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9536 - val_loss: 0.1078 - val_accuracy: 0.9516\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9556 - val_loss: 0.0927 - val_accuracy: 0.9839\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9516 - val_loss: 0.1134 - val_accuracy: 0.9516\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9617 - val_loss: 0.0924 - val_accuracy: 0.9758\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9375 - val_loss: 0.1213 - val_accuracy: 0.9435\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9456 - val_loss: 0.0944 - val_accuracy: 0.9758\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9617 - val_loss: 0.1032 - val_accuracy: 0.9597\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9496 - val_loss: 0.0960 - val_accuracy: 0.9597\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9657 - val_loss: 0.0867 - val_accuracy: 0.9758\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9536 - val_loss: 0.1014 - val_accuracy: 0.9435\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9657 - val_loss: 0.0860 - val_accuracy: 0.9677\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9677 - val_loss: 0.1005 - val_accuracy: 0.9435\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9597 - val_loss: 0.0886 - val_accuracy: 0.9597\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1248 - accuracy: 0.9577 - val_loss: 0.0931 - val_accuracy: 0.9516\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9516 - val_loss: 0.0872 - val_accuracy: 0.9677\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9637 - val_loss: 0.0889 - val_accuracy: 0.9516\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9657 - val_loss: 0.0835 - val_accuracy: 0.9677\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 0.1137 - val_accuracy: 0.9435\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9597 - val_loss: 0.0852 - val_accuracy: 0.9597\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9637 - val_loss: 0.0929 - val_accuracy: 0.9516\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9536 - val_loss: 0.0886 - val_accuracy: 0.9516\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9718 - val_loss: 0.0782 - val_accuracy: 0.9758\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9698 - val_loss: 0.0975 - val_accuracy: 0.9516\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9597 - val_loss: 0.0781 - val_accuracy: 0.9677\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9637 - val_loss: 0.0735 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9617 - val_loss: 0.1094 - val_accuracy: 0.9355\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9516 - val_loss: 0.0821 - val_accuracy: 0.9597\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9556 - val_loss: 0.0730 - val_accuracy: 0.9839\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.1242 - val_accuracy: 0.9355\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9435 - val_loss: 0.0763 - val_accuracy: 0.9758\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9597 - val_loss: 0.0751 - val_accuracy: 0.9839\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9536 - val_loss: 0.0893 - val_accuracy: 0.9435\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9657 - val_loss: 0.0771 - val_accuracy: 0.9677\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9698 - val_loss: 0.0877 - val_accuracy: 0.9516\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9657 - val_loss: 0.0735 - val_accuracy: 0.9758\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9657 - val_loss: 0.0958 - val_accuracy: 0.9435\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9738 - val_loss: 0.0710 - val_accuracy: 0.9758\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9657 - val_loss: 0.0990 - val_accuracy: 0.9435\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9637 - val_loss: 0.0761 - val_accuracy: 0.9597\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 0.0837 - val_accuracy: 0.9435\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9637 - val_loss: 0.0739 - val_accuracy: 0.9677\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9657 - val_loss: 0.0783 - val_accuracy: 0.9516\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9758 - val_loss: 0.0680 - val_accuracy: 0.9758\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9657 - val_loss: 0.0905 - val_accuracy: 0.9435\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9556 - val_loss: 0.0902 - val_accuracy: 0.9435\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9415 - val_loss: 0.0778 - val_accuracy: 0.9839\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.9637 - val_loss: 0.1025 - val_accuracy: 0.9435\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9577 - val_loss: 0.0773 - val_accuracy: 0.9677\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1103 - accuracy: 0.9637 - val_loss: 0.1042 - val_accuracy: 0.9435\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9657 - val_loss: 0.0667 - val_accuracy: 0.9758\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9617 - val_loss: 0.0750 - val_accuracy: 0.9597\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9718 - val_loss: 0.0723 - val_accuracy: 0.9677\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9698 - val_loss: 0.0722 - val_accuracy: 0.9677\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9738 - val_loss: 0.0703 - val_accuracy: 0.9677\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9677 - val_loss: 0.0738 - val_accuracy: 0.9597\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9657 - val_loss: 0.0669 - val_accuracy: 0.9758\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9657 - val_loss: 0.0792 - val_accuracy: 0.9516\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9718 - val_loss: 0.0691 - val_accuracy: 0.9758\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.0759 - val_accuracy: 0.9516\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9718 - val_loss: 0.0732 - val_accuracy: 0.9677\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9718 - val_loss: 0.0753 - val_accuracy: 0.9516\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9698 - val_loss: 0.0669 - val_accuracy: 0.9677\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9698 - val_loss: 0.0699 - val_accuracy: 0.9677\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 0.0697 - val_accuracy: 0.9677\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9698 - val_loss: 0.0748 - val_accuracy: 0.9597\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9637 - val_loss: 0.0661 - val_accuracy: 0.9758\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9677 - val_loss: 0.0658 - val_accuracy: 0.9758\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9677 - val_loss: 0.0800 - val_accuracy: 0.9435\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9738 - val_loss: 0.0671 - val_accuracy: 0.9758\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9738 - val_loss: 0.0771 - val_accuracy: 0.9516\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9718 - val_loss: 0.0641 - val_accuracy: 0.9758\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9718 - val_loss: 0.0740 - val_accuracy: 0.9597\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9698 - val_loss: 0.0749 - val_accuracy: 0.9516\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9556 - val_loss: 0.0673 - val_accuracy: 0.9677\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9375 - val_loss: 0.0733 - val_accuracy: 0.9597\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9738 - val_loss: 0.0754 - val_accuracy: 0.9516\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9758 - val_loss: 0.0672 - val_accuracy: 0.9677\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9677 - val_loss: 0.0776 - val_accuracy: 0.9516\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9718 - val_loss: 0.0626 - val_accuracy: 0.9758\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.0693 - val_accuracy: 0.9597\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9677 - val_loss: 0.0808 - val_accuracy: 0.9516\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9698 - val_loss: 0.0661 - val_accuracy: 0.9677\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9677 - val_loss: 0.0738 - val_accuracy: 0.9435\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9738 - val_loss: 0.0665 - val_accuracy: 0.9677\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.0641 - val_accuracy: 0.9758\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9677 - val_loss: 0.0739 - val_accuracy: 0.9516\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9778 - val_loss: 0.0621 - val_accuracy: 0.9758\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9738 - val_loss: 0.0766 - val_accuracy: 0.9516\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.0599 - val_accuracy: 0.9758\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.0843 - val_accuracy: 0.9355\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9597 - val_loss: 0.0654 - val_accuracy: 0.9677\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.0594 - val_accuracy: 0.9758\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9758 - val_loss: 0.0651 - val_accuracy: 0.9677\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9738 - val_loss: 0.0771 - val_accuracy: 0.9516\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9738 - val_loss: 0.0630 - val_accuracy: 0.9758\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9615\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.9809 - accuracy: 0.6431 - val_loss: 0.6187 - val_accuracy: 0.7903\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5997 - accuracy: 0.6895 - val_loss: 0.5182 - val_accuracy: 0.7177\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7460 - val_loss: 0.4483 - val_accuracy: 0.7903\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7863 - val_loss: 0.4082 - val_accuracy: 0.8468\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8044 - val_loss: 0.3776 - val_accuracy: 0.8226\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8286 - val_loss: 0.3504 - val_accuracy: 0.8468\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8387 - val_loss: 0.3388 - val_accuracy: 0.8306\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8387 - val_loss: 0.3193 - val_accuracy: 0.8548\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8448 - val_loss: 0.3294 - val_accuracy: 0.8548\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8548 - val_loss: 0.2981 - val_accuracy: 0.8710\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3040 - accuracy: 0.8649 - val_loss: 0.2967 - val_accuracy: 0.8387\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8710 - val_loss: 0.2856 - val_accuracy: 0.8871\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8770 - val_loss: 0.2926 - val_accuracy: 0.8629\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.8871 - val_loss: 0.2724 - val_accuracy: 0.8710\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2713 - accuracy: 0.8851 - val_loss: 0.2688 - val_accuracy: 0.8790\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.8952 - val_loss: 0.2677 - val_accuracy: 0.8871\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.8891 - val_loss: 0.2558 - val_accuracy: 0.8952\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.9032 - val_loss: 0.2508 - val_accuracy: 0.8952\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2545 - accuracy: 0.9073 - val_loss: 0.2765 - val_accuracy: 0.8629\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2626 - accuracy: 0.8770 - val_loss: 0.2452 - val_accuracy: 0.9194\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.8810 - val_loss: 0.2423 - val_accuracy: 0.9032\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9214 - val_loss: 0.2438 - val_accuracy: 0.8952\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.9012 - val_loss: 0.2317 - val_accuracy: 0.9355\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.9173 - val_loss: 0.2464 - val_accuracy: 0.8629\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.9153 - val_loss: 0.2231 - val_accuracy: 0.9113\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2258 - accuracy: 0.9012 - val_loss: 0.2221 - val_accuracy: 0.9032\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9274 - val_loss: 0.2313 - val_accuracy: 0.8790\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9153 - val_loss: 0.2124 - val_accuracy: 0.9274\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9274 - val_loss: 0.2136 - val_accuracy: 0.9032\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9194 - val_loss: 0.2045 - val_accuracy: 0.9274\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1996 - accuracy: 0.9315 - val_loss: 0.2033 - val_accuracy: 0.9113\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.9355 - val_loss: 0.2069 - val_accuracy: 0.9032\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1935 - accuracy: 0.9315 - val_loss: 0.1940 - val_accuracy: 0.9355\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1875 - accuracy: 0.9395 - val_loss: 0.2007 - val_accuracy: 0.9032\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9274 - val_loss: 0.1879 - val_accuracy: 0.9194\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1851 - accuracy: 0.9415 - val_loss: 0.1864 - val_accuracy: 0.9355\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1854 - accuracy: 0.9214 - val_loss: 0.1821 - val_accuracy: 0.9435\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9355 - val_loss: 0.1796 - val_accuracy: 0.9274\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9516 - val_loss: 0.1805 - val_accuracy: 0.9194\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9435 - val_loss: 0.1816 - val_accuracy: 0.9113\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.9315 - val_loss: 0.1699 - val_accuracy: 0.9355\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.9315 - val_loss: 0.1838 - val_accuracy: 0.9113\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9516 - val_loss: 0.1660 - val_accuracy: 0.9435\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9415 - val_loss: 0.1692 - val_accuracy: 0.9274\n",
      "Epoch 45/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1591 - accuracy: 0.9395 - val_loss: 0.1608 - val_accuracy: 0.9435\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1557 - accuracy: 0.9536 - val_loss: 0.1672 - val_accuracy: 0.9355\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.9476 - val_loss: 0.1661 - val_accuracy: 0.9194\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9375 - val_loss: 0.1558 - val_accuracy: 0.9435\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9435 - val_loss: 0.1659 - val_accuracy: 0.9194\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9395 - val_loss: 0.1542 - val_accuracy: 0.9435\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9476 - val_loss: 0.1610 - val_accuracy: 0.9355\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9456 - val_loss: 0.1530 - val_accuracy: 0.9435\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.9456 - val_loss: 0.1486 - val_accuracy: 0.9435\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.9536 - val_loss: 0.1505 - val_accuracy: 0.9355\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9435 - val_loss: 0.1620 - val_accuracy: 0.9194\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9496 - val_loss: 0.1455 - val_accuracy: 0.9435\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9536 - val_loss: 0.1412 - val_accuracy: 0.9516\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9556 - val_loss: 0.1745 - val_accuracy: 0.9113\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.9476 - val_loss: 0.1444 - val_accuracy: 0.9355\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9617 - val_loss: 0.1523 - val_accuracy: 0.9274\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9577 - val_loss: 0.1435 - val_accuracy: 0.9355\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.9516 - val_loss: 0.1737 - val_accuracy: 0.9113\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9476 - val_loss: 0.1338 - val_accuracy: 0.9597\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9516 - val_loss: 0.1430 - val_accuracy: 0.9274\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9597 - val_loss: 0.1470 - val_accuracy: 0.9355\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9617 - val_loss: 0.1453 - val_accuracy: 0.9355\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9577 - val_loss: 0.1507 - val_accuracy: 0.9355\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9556 - val_loss: 0.1326 - val_accuracy: 0.9516\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9617 - val_loss: 0.1481 - val_accuracy: 0.9435\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9577 - val_loss: 0.1319 - val_accuracy: 0.9435\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9556 - val_loss: 0.1398 - val_accuracy: 0.9516\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9556 - val_loss: 0.1704 - val_accuracy: 0.9113\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9516 - val_loss: 0.1271 - val_accuracy: 0.9516\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9657 - val_loss: 0.1374 - val_accuracy: 0.9435\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9556 - val_loss: 0.1316 - val_accuracy: 0.9355\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9577 - val_loss: 0.1610 - val_accuracy: 0.9274\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9556 - val_loss: 0.1309 - val_accuracy: 0.9516\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9496 - val_loss: 0.1294 - val_accuracy: 0.9435\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9617 - val_loss: 0.1548 - val_accuracy: 0.9194\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.9637 - val_loss: 0.1409 - val_accuracy: 0.9355\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9577 - val_loss: 0.1266 - val_accuracy: 0.9516\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9597 - val_loss: 0.1579 - val_accuracy: 0.9194\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9617 - val_loss: 0.1257 - val_accuracy: 0.9516\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9617 - val_loss: 0.1537 - val_accuracy: 0.9194\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9556 - val_loss: 0.1380 - val_accuracy: 0.9355\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9597 - val_loss: 0.1313 - val_accuracy: 0.9516\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.1402 - val_accuracy: 0.9355\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9637 - val_loss: 0.1640 - val_accuracy: 0.9194\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9536 - val_loss: 0.1391 - val_accuracy: 0.9355\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9577 - val_loss: 0.1289 - val_accuracy: 0.9435\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9698 - val_loss: 0.1471 - val_accuracy: 0.9355\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9637 - val_loss: 0.1384 - val_accuracy: 0.9355\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9657 - val_loss: 0.1409 - val_accuracy: 0.9355\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9637 - val_loss: 0.1390 - val_accuracy: 0.9355\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9617 - val_loss: 0.1272 - val_accuracy: 0.9435\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9698 - val_loss: 0.1501 - val_accuracy: 0.9355\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9536 - val_loss: 0.1240 - val_accuracy: 0.9597\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9556 - val_loss: 0.1399 - val_accuracy: 0.9355\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9657 - val_loss: 0.1467 - val_accuracy: 0.9355\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9637 - val_loss: 0.1316 - val_accuracy: 0.9355\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9657 - val_loss: 0.1376 - val_accuracy: 0.9355\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9677 - val_loss: 0.1421 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 0.1528 - val_accuracy: 0.9355\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9637 - val_loss: 0.1499 - val_accuracy: 0.9355\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9617 - val_loss: 0.1571 - val_accuracy: 0.9274\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9597 - val_loss: 0.1380 - val_accuracy: 0.9355\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9637 - val_loss: 0.1455 - val_accuracy: 0.9355\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.1283 - val_accuracy: 0.9435\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9698 - val_loss: 0.1954 - val_accuracy: 0.9113\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9577 - val_loss: 0.1240 - val_accuracy: 0.9516\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9516 - val_loss: 0.1643 - val_accuracy: 0.9113\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9718 - val_loss: 0.1312 - val_accuracy: 0.9355\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 0.1653 - val_accuracy: 0.9113\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9637 - val_loss: 0.1373 - val_accuracy: 0.9355\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9718 - val_loss: 0.1545 - val_accuracy: 0.9274\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9738 - val_loss: 0.1519 - val_accuracy: 0.9355\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9657 - val_loss: 0.1427 - val_accuracy: 0.9274\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9657 - val_loss: 0.1572 - val_accuracy: 0.9274\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9738 - val_loss: 0.1457 - val_accuracy: 0.9355\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9637 - val_loss: 0.1352 - val_accuracy: 0.9355\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9677 - val_loss: 0.1724 - val_accuracy: 0.9113\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9657 - val_loss: 0.1255 - val_accuracy: 0.9516\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9698 - val_loss: 0.1944 - val_accuracy: 0.9113\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9637 - val_loss: 0.1350 - val_accuracy: 0.9435\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9718 - val_loss: 0.1425 - val_accuracy: 0.9355\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9698 - val_loss: 0.1459 - val_accuracy: 0.9355\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9677 - val_loss: 0.1498 - val_accuracy: 0.9355\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9758 - val_loss: 0.1592 - val_accuracy: 0.9274\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.1412 - val_accuracy: 0.9274\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.1628 - val_accuracy: 0.9194\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9718 - val_loss: 0.1408 - val_accuracy: 0.9274\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9758 - val_loss: 0.1630 - val_accuracy: 0.9194\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9698 - val_loss: 0.1519 - val_accuracy: 0.9274\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9698 - val_loss: 0.1446 - val_accuracy: 0.9274\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9677 - val_loss: 0.1384 - val_accuracy: 0.9435\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9738 - val_loss: 0.1622 - val_accuracy: 0.9274\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9718 - val_loss: 0.1796 - val_accuracy: 0.9113\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9698 - val_loss: 0.1382 - val_accuracy: 0.9355\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.1821 - val_accuracy: 0.9113\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9778 - val_loss: 0.1420 - val_accuracy: 0.9355\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.1580 - val_accuracy: 0.9274\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9677 - val_loss: 0.1378 - val_accuracy: 0.9274\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9657 - val_loss: 0.1802 - val_accuracy: 0.9113\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9738 - val_loss: 0.1575 - val_accuracy: 0.9274\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9738 - val_loss: 0.1648 - val_accuracy: 0.9274\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9778 - val_loss: 0.1493 - val_accuracy: 0.9274\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9758 - val_loss: 0.1626 - val_accuracy: 0.9274\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9839 - val_loss: 0.1569 - val_accuracy: 0.9274\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9718 - val_loss: 0.1637 - val_accuracy: 0.9274\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 0.1672 - val_accuracy: 0.9194\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9423\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7357 - accuracy: 0.5706 - val_loss: 0.5674 - val_accuracy: 0.6774\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.6915 - val_loss: 0.4894 - val_accuracy: 0.7097\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7077 - val_loss: 0.4365 - val_accuracy: 0.7258\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7379 - val_loss: 0.4189 - val_accuracy: 0.7661\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7581 - val_loss: 0.4115 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7601 - val_loss: 0.4008 - val_accuracy: 0.7742\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.7823 - val_loss: 0.3917 - val_accuracy: 0.7984\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.7903 - val_loss: 0.3868 - val_accuracy: 0.7903\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.7823 - val_loss: 0.3801 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.7883 - val_loss: 0.3776 - val_accuracy: 0.8306\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8105 - val_loss: 0.3656 - val_accuracy: 0.8226\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8246 - val_loss: 0.3580 - val_accuracy: 0.8306\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8427 - val_loss: 0.3518 - val_accuracy: 0.8468\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8448 - val_loss: 0.3501 - val_accuracy: 0.8468\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8730 - val_loss: 0.3444 - val_accuracy: 0.8468\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8649 - val_loss: 0.3319 - val_accuracy: 0.8871\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8790 - val_loss: 0.3251 - val_accuracy: 0.8629\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8730 - val_loss: 0.3214 - val_accuracy: 0.9194\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8831 - val_loss: 0.3233 - val_accuracy: 0.8548\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8810 - val_loss: 0.3283 - val_accuracy: 0.9113\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8669 - val_loss: 0.2962 - val_accuracy: 0.8790\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8851 - val_loss: 0.2910 - val_accuracy: 0.8710\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2853 - accuracy: 0.8891 - val_loss: 0.2872 - val_accuracy: 0.8710\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9012 - val_loss: 0.2759 - val_accuracy: 0.8790\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2736 - accuracy: 0.8831 - val_loss: 0.2782 - val_accuracy: 0.9274\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.8891 - val_loss: 0.2663 - val_accuracy: 0.8710\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.9012 - val_loss: 0.2650 - val_accuracy: 0.9355\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9052 - val_loss: 0.2547 - val_accuracy: 0.9032\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2436 - accuracy: 0.9073 - val_loss: 0.2503 - val_accuracy: 0.9194\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2368 - accuracy: 0.9012 - val_loss: 0.2451 - val_accuracy: 0.8952\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9173 - val_loss: 0.2415 - val_accuracy: 0.9355\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9093 - val_loss: 0.2336 - val_accuracy: 0.9274\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9214 - val_loss: 0.2331 - val_accuracy: 0.8871\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2164 - accuracy: 0.9214 - val_loss: 0.2256 - val_accuracy: 0.8952\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9153 - val_loss: 0.2235 - val_accuracy: 0.9355\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9335 - val_loss: 0.2215 - val_accuracy: 0.8952\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9234 - val_loss: 0.2244 - val_accuracy: 0.9274\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9254 - val_loss: 0.2095 - val_accuracy: 0.9355\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1910 - accuracy: 0.9294 - val_loss: 0.2152 - val_accuracy: 0.9355\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9456 - val_loss: 0.2154 - val_accuracy: 0.8710\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1853 - accuracy: 0.9395 - val_loss: 0.2073 - val_accuracy: 0.9435\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9315 - val_loss: 0.1997 - val_accuracy: 0.9274\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9395 - val_loss: 0.1956 - val_accuracy: 0.9274\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9254 - val_loss: 0.2074 - val_accuracy: 0.9516\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9415 - val_loss: 0.1951 - val_accuracy: 0.9194\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9415 - val_loss: 0.1867 - val_accuracy: 0.9274\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.9294 - val_loss: 0.2019 - val_accuracy: 0.9435\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1633 - accuracy: 0.9496 - val_loss: 0.1876 - val_accuracy: 0.9274\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9456 - val_loss: 0.1877 - val_accuracy: 0.9516\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9476 - val_loss: 0.1863 - val_accuracy: 0.9355\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9415 - val_loss: 0.1880 - val_accuracy: 0.9435\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9556 - val_loss: 0.1777 - val_accuracy: 0.9435\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9597 - val_loss: 0.1804 - val_accuracy: 0.9194\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9315 - val_loss: 0.1885 - val_accuracy: 0.9516\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9577 - val_loss: 0.1760 - val_accuracy: 0.9355\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9516 - val_loss: 0.1845 - val_accuracy: 0.9435\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9577 - val_loss: 0.1689 - val_accuracy: 0.9435\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9637 - val_loss: 0.1676 - val_accuracy: 0.9516\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9617 - val_loss: 0.1648 - val_accuracy: 0.9435\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9698 - val_loss: 0.1632 - val_accuracy: 0.9435\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9435\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9556 - val_loss: 0.1635 - val_accuracy: 0.9597\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9657 - val_loss: 0.1635 - val_accuracy: 0.9516\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9718 - val_loss: 0.1622 - val_accuracy: 0.9435\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 0.1573 - val_accuracy: 0.9516\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9798 - val_loss: 0.1583 - val_accuracy: 0.9435\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9597 - val_loss: 0.1649 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9456 - val_loss: 0.1702 - val_accuracy: 0.9516\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9698 - val_loss: 0.1669 - val_accuracy: 0.9274\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9556 - val_loss: 0.1673 - val_accuracy: 0.9516\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9577 - val_loss: 0.1490 - val_accuracy: 0.9516\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9677 - val_loss: 0.1506 - val_accuracy: 0.9435\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9597 - val_loss: 0.1528 - val_accuracy: 0.9516\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9677 - val_loss: 0.1524 - val_accuracy: 0.9597\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9677 - val_loss: 0.1476 - val_accuracy: 0.9435\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9597 - val_loss: 0.1504 - val_accuracy: 0.9516\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9677 - val_loss: 0.1569 - val_accuracy: 0.9597\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9597 - val_loss: 0.1448 - val_accuracy: 0.9516\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9597 - val_loss: 0.1569 - val_accuracy: 0.9516\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9597 - val_loss: 0.1488 - val_accuracy: 0.9516\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9677 - val_loss: 0.1428 - val_accuracy: 0.9435\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.1504 - val_accuracy: 0.9677\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9597 - val_loss: 0.1437 - val_accuracy: 0.9516\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.1518 - val_accuracy: 0.9597\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9657 - val_loss: 0.1428 - val_accuracy: 0.9516\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9718 - val_loss: 0.1489 - val_accuracy: 0.9435\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9657 - val_loss: 0.1689 - val_accuracy: 0.9274\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1076 - accuracy: 0.9556 - val_loss: 0.1534 - val_accuracy: 0.9516\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9698 - val_loss: 0.1439 - val_accuracy: 0.9516\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 0.1486 - val_accuracy: 0.9597\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9698 - val_loss: 0.1406 - val_accuracy: 0.9516\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9677 - val_loss: 0.1412 - val_accuracy: 0.9597\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9698 - val_loss: 0.1417 - val_accuracy: 0.9597\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9778 - val_loss: 0.1423 - val_accuracy: 0.9597\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9758 - val_loss: 0.1501 - val_accuracy: 0.9435\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9718 - val_loss: 0.1425 - val_accuracy: 0.9516\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9718 - val_loss: 0.1403 - val_accuracy: 0.9516\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9758 - val_loss: 0.1451 - val_accuracy: 0.9516\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9778 - val_loss: 0.1395 - val_accuracy: 0.9516\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9738 - val_loss: 0.1430 - val_accuracy: 0.9597\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9758 - val_loss: 0.1397 - val_accuracy: 0.9516\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 0.1411 - val_accuracy: 0.9516\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9718 - val_loss: 0.1475 - val_accuracy: 0.9516\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9778 - val_loss: 0.1476 - val_accuracy: 0.9435\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9758 - val_loss: 0.1404 - val_accuracy: 0.9597\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9698 - val_loss: 0.1438 - val_accuracy: 0.9516\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9698 - val_loss: 0.1430 - val_accuracy: 0.9597\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9738 - val_loss: 0.1518 - val_accuracy: 0.9435\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9597 - val_loss: 0.1405 - val_accuracy: 0.9597\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.1567 - val_accuracy: 0.9516\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9516 - val_loss: 0.1600 - val_accuracy: 0.9355\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9778 - val_loss: 0.1478 - val_accuracy: 0.9597\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9718 - val_loss: 0.1403 - val_accuracy: 0.9597\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9819 - val_loss: 0.1569 - val_accuracy: 0.9355\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9819 - val_loss: 0.1403 - val_accuracy: 0.9597\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9698 - val_loss: 0.1417 - val_accuracy: 0.9597\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9798 - val_loss: 0.1417 - val_accuracy: 0.9516\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 0.1466 - val_accuracy: 0.9677\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9798 - val_loss: 0.1393 - val_accuracy: 0.9597\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.1383 - val_accuracy: 0.9516\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9758 - val_loss: 0.1431 - val_accuracy: 0.9597\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.1429 - val_accuracy: 0.9435\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9738 - val_loss: 0.1449 - val_accuracy: 0.9677\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9738 - val_loss: 0.1504 - val_accuracy: 0.9597\n",
      "Epoch 125/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9677 - val_loss: 0.1382 - val_accuracy: 0.9516\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9798 - val_loss: 0.1486 - val_accuracy: 0.9516\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9798 - val_loss: 0.1394 - val_accuracy: 0.9597\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9819 - val_loss: 0.1421 - val_accuracy: 0.9677\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 0.1390 - val_accuracy: 0.9597\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9798 - val_loss: 0.1381 - val_accuracy: 0.9516\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9798 - val_loss: 0.1495 - val_accuracy: 0.9516\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9718 - val_loss: 0.1429 - val_accuracy: 0.9516\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9798 - val_loss: 0.1401 - val_accuracy: 0.9516\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9798 - val_loss: 0.1582 - val_accuracy: 0.9516\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9698 - val_loss: 0.1422 - val_accuracy: 0.9516\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9758 - val_loss: 0.1408 - val_accuracy: 0.9516\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9819 - val_loss: 0.1459 - val_accuracy: 0.9597\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.1396 - val_accuracy: 0.9516\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9798 - val_loss: 0.1424 - val_accuracy: 0.9597\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9698 - val_loss: 0.1425 - val_accuracy: 0.9516\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9738 - val_loss: 0.1486 - val_accuracy: 0.9435\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9738 - val_loss: 0.1428 - val_accuracy: 0.9597\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9758 - val_loss: 0.1508 - val_accuracy: 0.9597\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9798 - val_loss: 0.1512 - val_accuracy: 0.9435\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9738 - val_loss: 0.1548 - val_accuracy: 0.9597\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9718 - val_loss: 0.1738 - val_accuracy: 0.9435\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9819 - val_loss: 0.1437 - val_accuracy: 0.9597\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.1454 - val_accuracy: 0.9516\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9738 - val_loss: 0.1449 - val_accuracy: 0.9516\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9758 - val_loss: 0.1540 - val_accuracy: 0.9516\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9423\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.8058 - accuracy: 0.6109 - val_loss: 1.0498 - val_accuracy: 0.5645\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7368 - accuracy: 0.5847 - val_loss: 0.5252 - val_accuracy: 0.7419\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5794 - accuracy: 0.7319 - val_loss: 0.4777 - val_accuracy: 0.7500\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7480 - val_loss: 0.4191 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8105 - val_loss: 0.3687 - val_accuracy: 0.7903\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8387 - val_loss: 0.3482 - val_accuracy: 0.8952\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8387 - val_loss: 0.3387 - val_accuracy: 0.8387\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8327 - val_loss: 0.3390 - val_accuracy: 0.8548\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8367 - val_loss: 0.3203 - val_accuracy: 0.8790\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8488 - val_loss: 0.3220 - val_accuracy: 0.8871\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8548 - val_loss: 0.3148 - val_accuracy: 0.8871\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8488 - val_loss: 0.3125 - val_accuracy: 0.8871\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8569 - val_loss: 0.3104 - val_accuracy: 0.8790\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8589 - val_loss: 0.2991 - val_accuracy: 0.8871\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8669 - val_loss: 0.3018 - val_accuracy: 0.8871\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8609 - val_loss: 0.2960 - val_accuracy: 0.8790\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8690 - val_loss: 0.2934 - val_accuracy: 0.8952\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8770 - val_loss: 0.2868 - val_accuracy: 0.9113\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8871 - val_loss: 0.2771 - val_accuracy: 0.8871\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8669 - val_loss: 0.3020 - val_accuracy: 0.8871\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.8851 - val_loss: 0.2622 - val_accuracy: 0.9032\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.8810 - val_loss: 0.2871 - val_accuracy: 0.8790\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8911 - val_loss: 0.2630 - val_accuracy: 0.9032\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2719 - accuracy: 0.8972 - val_loss: 0.2675 - val_accuracy: 0.9032\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8831 - val_loss: 0.2664 - val_accuracy: 0.8952\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.8972 - val_loss: 0.2549 - val_accuracy: 0.8871\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.8831 - val_loss: 0.2511 - val_accuracy: 0.9032\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8952 - val_loss: 0.2429 - val_accuracy: 0.9113\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9012 - val_loss: 0.2557 - val_accuracy: 0.9032\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2461 - accuracy: 0.9052 - val_loss: 0.2412 - val_accuracy: 0.9113\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9113 - val_loss: 0.2592 - val_accuracy: 0.8871\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2317 - accuracy: 0.9093 - val_loss: 0.2428 - val_accuracy: 0.9032\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2278 - accuracy: 0.9153 - val_loss: 0.2426 - val_accuracy: 0.9032\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2226 - accuracy: 0.9052 - val_loss: 0.2399 - val_accuracy: 0.8871\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 0.2457 - val_accuracy: 0.8871\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9194 - val_loss: 0.2284 - val_accuracy: 0.9032\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9194 - val_loss: 0.2444 - val_accuracy: 0.8790\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9234 - val_loss: 0.2360 - val_accuracy: 0.8710\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9194 - val_loss: 0.2395 - val_accuracy: 0.8871\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9153 - val_loss: 0.2254 - val_accuracy: 0.8871\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9274 - val_loss: 0.2273 - val_accuracy: 0.8710\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1930 - accuracy: 0.9214 - val_loss: 0.2328 - val_accuracy: 0.8952\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9153 - val_loss: 0.2230 - val_accuracy: 0.8710\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9194 - val_loss: 0.2386 - val_accuracy: 0.8871\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9335 - val_loss: 0.2241 - val_accuracy: 0.8710\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9274 - val_loss: 0.2313 - val_accuracy: 0.8710\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9234 - val_loss: 0.2169 - val_accuracy: 0.9113\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1793 - accuracy: 0.9395 - val_loss: 0.2298 - val_accuracy: 0.8629\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9194 - val_loss: 0.2241 - val_accuracy: 0.8952\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9234 - val_loss: 0.2320 - val_accuracy: 0.8871\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9355 - val_loss: 0.2283 - val_accuracy: 0.9032\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9355 - val_loss: 0.2086 - val_accuracy: 0.8790\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9435 - val_loss: 0.2566 - val_accuracy: 0.8710\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.9315 - val_loss: 0.2166 - val_accuracy: 0.8790\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.9355 - val_loss: 0.2093 - val_accuracy: 0.9032\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9315 - val_loss: 0.2447 - val_accuracy: 0.8790\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 0.9476 - val_loss: 0.2084 - val_accuracy: 0.8952\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9335 - val_loss: 0.2349 - val_accuracy: 0.8871\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.9456 - val_loss: 0.2140 - val_accuracy: 0.8790\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9375 - val_loss: 0.2206 - val_accuracy: 0.8790\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9415 - val_loss: 0.2103 - val_accuracy: 0.8871\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9315 - val_loss: 0.1973 - val_accuracy: 0.9113\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9355 - val_loss: 0.2158 - val_accuracy: 0.8952\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9315 - val_loss: 0.2015 - val_accuracy: 0.9113\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9415 - val_loss: 0.2633 - val_accuracy: 0.8548\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9395 - val_loss: 0.2056 - val_accuracy: 0.9113\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9496 - val_loss: 0.2076 - val_accuracy: 0.9032\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.9375 - val_loss: 0.2156 - val_accuracy: 0.8871\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9476 - val_loss: 0.2043 - val_accuracy: 0.9113\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9516 - val_loss: 0.2133 - val_accuracy: 0.9032\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9476 - val_loss: 0.2095 - val_accuracy: 0.8871\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9435 - val_loss: 0.2011 - val_accuracy: 0.9032\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9456 - val_loss: 0.2328 - val_accuracy: 0.8710\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9415 - val_loss: 0.1938 - val_accuracy: 0.9194\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9617 - val_loss: 0.2186 - val_accuracy: 0.9032\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9516 - val_loss: 0.2077 - val_accuracy: 0.8952\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9577 - val_loss: 0.1952 - val_accuracy: 0.9194\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9415 - val_loss: 0.2135 - val_accuracy: 0.9032\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9476 - val_loss: 0.2058 - val_accuracy: 0.8952\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9516 - val_loss: 0.2203 - val_accuracy: 0.8952\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9577 - val_loss: 0.1927 - val_accuracy: 0.9194\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9476 - val_loss: 0.2184 - val_accuracy: 0.8952\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9536 - val_loss: 0.2124 - val_accuracy: 0.8952\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9597 - val_loss: 0.2084 - val_accuracy: 0.9194\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9516 - val_loss: 0.2114 - val_accuracy: 0.9113\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9597 - val_loss: 0.1905 - val_accuracy: 0.9113\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9597 - val_loss: 0.2256 - val_accuracy: 0.8710\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9536 - val_loss: 0.1877 - val_accuracy: 0.9113\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9476 - val_loss: 0.2451 - val_accuracy: 0.8468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9476 - val_loss: 0.1852 - val_accuracy: 0.9113\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9617 - val_loss: 0.2110 - val_accuracy: 0.8952\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9516 - val_loss: 0.2197 - val_accuracy: 0.8871\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9456 - val_loss: 0.1885 - val_accuracy: 0.9113\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9415 - val_loss: 0.2002 - val_accuracy: 0.8952\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9536 - val_loss: 0.2312 - val_accuracy: 0.8871\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 0.1887 - val_accuracy: 0.9113\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9456 - val_loss: 0.2612 - val_accuracy: 0.8548\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9637 - val_loss: 0.2039 - val_accuracy: 0.8952\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9556 - val_loss: 0.2301 - val_accuracy: 0.8790\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9637 - val_loss: 0.1886 - val_accuracy: 0.9194\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9536 - val_loss: 0.2331 - val_accuracy: 0.8629\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9617 - val_loss: 0.2000 - val_accuracy: 0.9194\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9617 - val_loss: 0.1995 - val_accuracy: 0.9194\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9657 - val_loss: 0.1896 - val_accuracy: 0.9274\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.9657 - val_loss: 0.2251 - val_accuracy: 0.8871\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9657 - val_loss: 0.1935 - val_accuracy: 0.9274\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9657 - val_loss: 0.2027 - val_accuracy: 0.9194\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9617 - val_loss: 0.2133 - val_accuracy: 0.8952\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9617 - val_loss: 0.1988 - val_accuracy: 0.9274\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 0.2118 - val_accuracy: 0.8952\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9718 - val_loss: 0.2062 - val_accuracy: 0.9113\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9577 - val_loss: 0.1947 - val_accuracy: 0.9194\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9637 - val_loss: 0.2043 - val_accuracy: 0.9194\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9617 - val_loss: 0.2002 - val_accuracy: 0.9194\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9698 - val_loss: 0.2058 - val_accuracy: 0.9194\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9657 - val_loss: 0.2029 - val_accuracy: 0.9194\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 0.2013 - val_accuracy: 0.9194\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9718 - val_loss: 0.2056 - val_accuracy: 0.9274\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9677 - val_loss: 0.2164 - val_accuracy: 0.9032\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9657 - val_loss: 0.1897 - val_accuracy: 0.9194\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9637 - val_loss: 0.2187 - val_accuracy: 0.9032\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9536 - val_loss: 0.2254 - val_accuracy: 0.8790\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9657 - val_loss: 0.1934 - val_accuracy: 0.9274\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9698 - val_loss: 0.2604 - val_accuracy: 0.8468\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9738 - val_loss: 0.1922 - val_accuracy: 0.9194\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9657 - val_loss: 0.2308 - val_accuracy: 0.8629\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9617 - val_loss: 0.2100 - val_accuracy: 0.9194\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9637 - val_loss: 0.1909 - val_accuracy: 0.9274\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9637 - val_loss: 0.2203 - val_accuracy: 0.9032\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9657 - val_loss: 0.1974 - val_accuracy: 0.9274\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.2138 - val_accuracy: 0.9032\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.2107 - val_accuracy: 0.9194\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.2185 - val_accuracy: 0.9194\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 0.1927 - val_accuracy: 0.9274\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9718 - val_loss: 0.2200 - val_accuracy: 0.8952\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9637 - val_loss: 0.1968 - val_accuracy: 0.9274\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9718 - val_loss: 0.2161 - val_accuracy: 0.9194\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9698 - val_loss: 0.1957 - val_accuracy: 0.9274\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9597 - val_loss: 0.2608 - val_accuracy: 0.8548\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9637 - val_loss: 0.1970 - val_accuracy: 0.9274\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9677 - val_loss: 0.2107 - val_accuracy: 0.9194\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9698 - val_loss: 0.2141 - val_accuracy: 0.9113\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9738 - val_loss: 0.2121 - val_accuracy: 0.9032\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9677 - val_loss: 0.1994 - val_accuracy: 0.9274\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9718 - val_loss: 0.2148 - val_accuracy: 0.9194\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.2002 - val_accuracy: 0.9274\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9677 - val_loss: 0.2035 - val_accuracy: 0.9194\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9617 - val_loss: 0.2417 - val_accuracy: 0.8629\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9657 - val_loss: 0.1904 - val_accuracy: 0.9194\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9657 - val_loss: 0.2519 - val_accuracy: 0.8548\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9359\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.6569 - accuracy: 0.3972 - val_loss: 0.7718 - val_accuracy: 0.5242\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6371 - val_loss: 0.5375 - val_accuracy: 0.7016\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7480 - val_loss: 0.4881 - val_accuracy: 0.6855\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7480 - val_loss: 0.4653 - val_accuracy: 0.7016\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7702 - val_loss: 0.4706 - val_accuracy: 0.7258\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.7843 - val_loss: 0.4516 - val_accuracy: 0.7339\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.7923 - val_loss: 0.4348 - val_accuracy: 0.7339\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8085 - val_loss: 0.4387 - val_accuracy: 0.7661\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8246 - val_loss: 0.4312 - val_accuracy: 0.7661\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8306 - val_loss: 0.4139 - val_accuracy: 0.7742\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8488 - val_loss: 0.4060 - val_accuracy: 0.7903\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8589 - val_loss: 0.3975 - val_accuracy: 0.8065\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8629 - val_loss: 0.3921 - val_accuracy: 0.8306\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8750 - val_loss: 0.3842 - val_accuracy: 0.8387\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8750 - val_loss: 0.3688 - val_accuracy: 0.8226\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8931 - val_loss: 0.3688 - val_accuracy: 0.8548\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8911 - val_loss: 0.3586 - val_accuracy: 0.8548\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8911 - val_loss: 0.3613 - val_accuracy: 0.8548\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.9032 - val_loss: 0.3361 - val_accuracy: 0.8548\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8992 - val_loss: 0.3432 - val_accuracy: 0.8548\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.9113 - val_loss: 0.3344 - val_accuracy: 0.8710\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.9012 - val_loss: 0.3195 - val_accuracy: 0.8871\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.9153 - val_loss: 0.3224 - val_accuracy: 0.8629\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9173 - val_loss: 0.3047 - val_accuracy: 0.9032\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9093 - val_loss: 0.3075 - val_accuracy: 0.8629\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.9274 - val_loss: 0.2908 - val_accuracy: 0.8871\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9234 - val_loss: 0.2843 - val_accuracy: 0.9032\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.9274 - val_loss: 0.2770 - val_accuracy: 0.9032\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9254 - val_loss: 0.2684 - val_accuracy: 0.9194\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9315 - val_loss: 0.2705 - val_accuracy: 0.8952\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9294 - val_loss: 0.2545 - val_accuracy: 0.9194\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9214 - val_loss: 0.2537 - val_accuracy: 0.9032\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.9375 - val_loss: 0.2641 - val_accuracy: 0.8790\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9335 - val_loss: 0.2400 - val_accuracy: 0.9274\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9435 - val_loss: 0.2616 - val_accuracy: 0.8790\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9214 - val_loss: 0.2271 - val_accuracy: 0.9355\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1874 - accuracy: 0.9415 - val_loss: 0.2445 - val_accuracy: 0.9113\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9375 - val_loss: 0.2378 - val_accuracy: 0.9194\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9335 - val_loss: 0.2116 - val_accuracy: 0.9435\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9496 - val_loss: 0.2429 - val_accuracy: 0.8871\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9496 - val_loss: 0.2132 - val_accuracy: 0.9355\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9435 - val_loss: 0.2262 - val_accuracy: 0.9113\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9375 - val_loss: 0.2122 - val_accuracy: 0.9435\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.9476 - val_loss: 0.2014 - val_accuracy: 0.9516\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.9516 - val_loss: 0.2084 - val_accuracy: 0.9355\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1566 - accuracy: 0.9395 - val_loss: 0.2025 - val_accuracy: 0.9435\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9435 - val_loss: 0.1953 - val_accuracy: 0.9435\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9496 - val_loss: 0.2135 - val_accuracy: 0.9274\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9435 - val_loss: 0.1899 - val_accuracy: 0.9516\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1487 - accuracy: 0.9536 - val_loss: 0.1827 - val_accuracy: 0.9597\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9476 - val_loss: 0.1761 - val_accuracy: 0.9516\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9476 - val_loss: 0.2023 - val_accuracy: 0.9274\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9657 - val_loss: 0.1690 - val_accuracy: 0.9516\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9536 - val_loss: 0.2106 - val_accuracy: 0.9194\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.9476 - val_loss: 0.1746 - val_accuracy: 0.9516\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9536 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9516 - val_loss: 0.1691 - val_accuracy: 0.9516\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9617 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9516 - val_loss: 0.1594 - val_accuracy: 0.9516\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9597 - val_loss: 0.1643 - val_accuracy: 0.9516\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9637 - val_loss: 0.2057 - val_accuracy: 0.9274\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1421 - accuracy: 0.9355 - val_loss: 0.1478 - val_accuracy: 0.9516\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9536 - val_loss: 0.1796 - val_accuracy: 0.9516\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9637 - val_loss: 0.1580 - val_accuracy: 0.9516\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9617 - val_loss: 0.1568 - val_accuracy: 0.9677\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9556 - val_loss: 0.1654 - val_accuracy: 0.9516\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9577 - val_loss: 0.1506 - val_accuracy: 0.9516\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.9677 - val_loss: 0.1580 - val_accuracy: 0.9516\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1438 - val_accuracy: 0.9516\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9556 - val_loss: 0.2064 - val_accuracy: 0.9194\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9577 - val_loss: 0.1376 - val_accuracy: 0.9597\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9556 - val_loss: 0.1645 - val_accuracy: 0.9516\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9657 - val_loss: 0.1377 - val_accuracy: 0.9597\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9698 - val_loss: 0.1582 - val_accuracy: 0.9516\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9617 - val_loss: 0.1474 - val_accuracy: 0.9516\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9677 - val_loss: 0.1390 - val_accuracy: 0.9597\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9637 - val_loss: 0.1509 - val_accuracy: 0.9516\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9597 - val_loss: 0.1409 - val_accuracy: 0.9597\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.1402 - val_accuracy: 0.9597\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9617 - val_loss: 0.1451 - val_accuracy: 0.9516\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9637 - val_loss: 0.1553 - val_accuracy: 0.9597\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9597 - val_loss: 0.1380 - val_accuracy: 0.9597\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9657 - val_loss: 0.1821 - val_accuracy: 0.9516\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9516 - val_loss: 0.1287 - val_accuracy: 0.9516\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9577 - val_loss: 0.1732 - val_accuracy: 0.9516\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9536 - val_loss: 0.1298 - val_accuracy: 0.9516\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9577 - val_loss: 0.1557 - val_accuracy: 0.9516\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9657 - val_loss: 0.1472 - val_accuracy: 0.9597\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9597 - val_loss: 0.1315 - val_accuracy: 0.9597\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9718 - val_loss: 0.1523 - val_accuracy: 0.9435\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9577 - val_loss: 0.1289 - val_accuracy: 0.9516\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9677 - val_loss: 0.1827 - val_accuracy: 0.9355\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1015 - accuracy: 0.9637 - val_loss: 0.1264 - val_accuracy: 0.9516\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9556 - val_loss: 0.1514 - val_accuracy: 0.9516\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9657 - val_loss: 0.1306 - val_accuracy: 0.9597\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9657 - val_loss: 0.1384 - val_accuracy: 0.9516\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9677 - val_loss: 0.1351 - val_accuracy: 0.9597\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9677 - val_loss: 0.1369 - val_accuracy: 0.9516\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9718 - val_loss: 0.1390 - val_accuracy: 0.9516\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9597 - val_loss: 0.1265 - val_accuracy: 0.9597\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9738 - val_loss: 0.1445 - val_accuracy: 0.9516\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9657 - val_loss: 0.1252 - val_accuracy: 0.9597\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9657 - val_loss: 0.1338 - val_accuracy: 0.9516\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9677 - val_loss: 0.1351 - val_accuracy: 0.9597\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9617 - val_loss: 0.1298 - val_accuracy: 0.9597\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9617 - val_loss: 0.1514 - val_accuracy: 0.9597\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9677 - val_loss: 0.1281 - val_accuracy: 0.9597\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9677 - val_loss: 0.1296 - val_accuracy: 0.9597\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9657 - val_loss: 0.1482 - val_accuracy: 0.9435\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9597 - val_loss: 0.1207 - val_accuracy: 0.9516\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9617 - val_loss: 0.1984 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9637 - val_loss: 0.1232 - val_accuracy: 0.9597\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9617 - val_loss: 0.1358 - val_accuracy: 0.9516\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.1358 - val_accuracy: 0.9516\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9657 - val_loss: 0.1257 - val_accuracy: 0.9597\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9738 - val_loss: 0.1395 - val_accuracy: 0.9516\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9657 - val_loss: 0.1380 - val_accuracy: 0.9516\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9637 - val_loss: 0.1337 - val_accuracy: 0.9516\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9677 - val_loss: 0.1435 - val_accuracy: 0.9516\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9617 - val_loss: 0.1220 - val_accuracy: 0.9677\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9758 - val_loss: 0.1471 - val_accuracy: 0.9597\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 0.1271 - val_accuracy: 0.9597\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9718 - val_loss: 0.1344 - val_accuracy: 0.9516\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9677 - val_loss: 0.1255 - val_accuracy: 0.9597\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9677 - val_loss: 0.1286 - val_accuracy: 0.9516\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.1335 - val_accuracy: 0.9516\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9657 - val_loss: 0.1234 - val_accuracy: 0.9677\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 0.1382 - val_accuracy: 0.9435\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9698 - val_loss: 0.1246 - val_accuracy: 0.9597\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9677 - val_loss: 0.1279 - val_accuracy: 0.9516\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9677 - val_loss: 0.1263 - val_accuracy: 0.9597\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9637 - val_loss: 0.1236 - val_accuracy: 0.9597\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9758 - val_loss: 0.1450 - val_accuracy: 0.9435\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9718 - val_loss: 0.1412 - val_accuracy: 0.9516\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9677 - val_loss: 0.1238 - val_accuracy: 0.9597\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.1575 - val_accuracy: 0.9516\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9637 - val_loss: 0.1214 - val_accuracy: 0.9677\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9718 - val_loss: 0.1452 - val_accuracy: 0.9435\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9637 - val_loss: 0.1121 - val_accuracy: 0.9677\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.1658 - val_accuracy: 0.9516\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9657 - val_loss: 0.1278 - val_accuracy: 0.9597\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9738 - val_loss: 0.1295 - val_accuracy: 0.9516\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9738 - val_loss: 0.1260 - val_accuracy: 0.9516\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9738 - val_loss: 0.1392 - val_accuracy: 0.9516\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 0.1272 - val_accuracy: 0.9516\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9698 - val_loss: 0.1181 - val_accuracy: 0.9677\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.1404 - val_accuracy: 0.9516\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9718 - val_loss: 0.1332 - val_accuracy: 0.9435\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9677 - val_loss: 0.1162 - val_accuracy: 0.9677\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9698 - val_loss: 0.1539 - val_accuracy: 0.9597\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9744\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1.3552 - accuracy: 0.6331 - val_loss: 0.5118 - val_accuracy: 0.8145\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7802 - val_loss: 0.3943 - val_accuracy: 0.8871\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8327 - val_loss: 0.3619 - val_accuracy: 0.8710\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8508 - val_loss: 0.3524 - val_accuracy: 0.8871\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8508 - val_loss: 0.3373 - val_accuracy: 0.8871\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8569 - val_loss: 0.3164 - val_accuracy: 0.8710\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8468 - val_loss: 0.3212 - val_accuracy: 0.8871\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8649 - val_loss: 0.2929 - val_accuracy: 0.8790\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.8669 - val_loss: 0.3012 - val_accuracy: 0.8952\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.8690 - val_loss: 0.2783 - val_accuracy: 0.8790\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.8770 - val_loss: 0.2763 - val_accuracy: 0.9032\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8790 - val_loss: 0.2626 - val_accuracy: 0.8952\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.8891 - val_loss: 0.2659 - val_accuracy: 0.9113\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8871 - val_loss: 0.2529 - val_accuracy: 0.9194\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8992 - val_loss: 0.2503 - val_accuracy: 0.9194\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2716 - accuracy: 0.9012 - val_loss: 0.2421 - val_accuracy: 0.9194\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8871 - val_loss: 0.2345 - val_accuracy: 0.9274\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.9032 - val_loss: 0.2392 - val_accuracy: 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9032 - val_loss: 0.2302 - val_accuracy: 0.9274\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.8911 - val_loss: 0.2221 - val_accuracy: 0.9274\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9113 - val_loss: 0.2213 - val_accuracy: 0.9113\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9073 - val_loss: 0.2182 - val_accuracy: 0.9274\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.9194 - val_loss: 0.2089 - val_accuracy: 0.9194\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2379 - accuracy: 0.9214 - val_loss: 0.2031 - val_accuracy: 0.9274\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9073 - val_loss: 0.2088 - val_accuracy: 0.9274\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.9194 - val_loss: 0.1996 - val_accuracy: 0.9355\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9214 - val_loss: 0.1941 - val_accuracy: 0.9274\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9012 - val_loss: 0.2185 - val_accuracy: 0.9516\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2272 - accuracy: 0.9113 - val_loss: 0.1872 - val_accuracy: 0.9113\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2146 - accuracy: 0.9133 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9274 - val_loss: 0.1819 - val_accuracy: 0.9194\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.9194 - val_loss: 0.1985 - val_accuracy: 0.9516\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9214 - val_loss: 0.1753 - val_accuracy: 0.9435\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9214 - val_loss: 0.1808 - val_accuracy: 0.9355\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9335 - val_loss: 0.1741 - val_accuracy: 0.9274\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.9133 - val_loss: 0.1856 - val_accuracy: 0.9597\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9254 - val_loss: 0.1686 - val_accuracy: 0.9435\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.9153 - val_loss: 0.1743 - val_accuracy: 0.9435\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9294 - val_loss: 0.1641 - val_accuracy: 0.9435\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9274 - val_loss: 0.1611 - val_accuracy: 0.9435\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9294 - val_loss: 0.1608 - val_accuracy: 0.9435\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9214 - val_loss: 0.1546 - val_accuracy: 0.9435\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1832 - accuracy: 0.9456 - val_loss: 0.1505 - val_accuracy: 0.9516\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.9173 - val_loss: 0.1628 - val_accuracy: 0.9677\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9395 - val_loss: 0.1464 - val_accuracy: 0.9597\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9315 - val_loss: 0.1486 - val_accuracy: 0.9516\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9335 - val_loss: 0.1441 - val_accuracy: 0.9516\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9335 - val_loss: 0.1540 - val_accuracy: 0.9677\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.9375 - val_loss: 0.1425 - val_accuracy: 0.9597\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9395 - val_loss: 0.1451 - val_accuracy: 0.9516\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9274 - val_loss: 0.1660 - val_accuracy: 0.9597\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9335 - val_loss: 0.1406 - val_accuracy: 0.9597\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9456 - val_loss: 0.1354 - val_accuracy: 0.9516\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.9294 - val_loss: 0.1499 - val_accuracy: 0.9677\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9355 - val_loss: 0.1478 - val_accuracy: 0.9677\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9335 - val_loss: 0.1318 - val_accuracy: 0.9516\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9415 - val_loss: 0.1433 - val_accuracy: 0.9677\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9415 - val_loss: 0.1256 - val_accuracy: 0.9516\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9456 - val_loss: 0.1403 - val_accuracy: 0.9677\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1538 - accuracy: 0.9355 - val_loss: 0.1306 - val_accuracy: 0.9758\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.9536 - val_loss: 0.1241 - val_accuracy: 0.9516\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9456 - val_loss: 0.1505 - val_accuracy: 0.9677\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9395 - val_loss: 0.1208 - val_accuracy: 0.9516\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9395 - val_loss: 0.1184 - val_accuracy: 0.9435\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9435 - val_loss: 0.1232 - val_accuracy: 0.9758\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9516 - val_loss: 0.1174 - val_accuracy: 0.9516\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9395 - val_loss: 0.1276 - val_accuracy: 0.9758\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9516 - val_loss: 0.1137 - val_accuracy: 0.9435\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9456 - val_loss: 0.1127 - val_accuracy: 0.9516\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9476 - val_loss: 0.1483 - val_accuracy: 0.9597\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9456 - val_loss: 0.1169 - val_accuracy: 0.9677\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9395 - val_loss: 0.1285 - val_accuracy: 0.9677\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9597 - val_loss: 0.1063 - val_accuracy: 0.9516\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9355 - val_loss: 0.1826 - val_accuracy: 0.9032\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9476 - val_loss: 0.1055 - val_accuracy: 0.9516\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1352 - accuracy: 0.9516 - val_loss: 0.1142 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9435 - val_loss: 0.1129 - val_accuracy: 0.9677\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9637 - val_loss: 0.1043 - val_accuracy: 0.9597\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9415 - val_loss: 0.1280 - val_accuracy: 0.9677\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9536 - val_loss: 0.1029 - val_accuracy: 0.9516\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9456 - val_loss: 0.1067 - val_accuracy: 0.9677\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.9456 - val_loss: 0.1482 - val_accuracy: 0.9435\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9536 - val_loss: 0.0996 - val_accuracy: 0.9597\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1248 - accuracy: 0.9536 - val_loss: 0.1050 - val_accuracy: 0.9677\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9556 - val_loss: 0.1143 - val_accuracy: 0.9758\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9435 - val_loss: 0.0980 - val_accuracy: 0.9597\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9516 - val_loss: 0.1303 - val_accuracy: 0.9677\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.9496 - val_loss: 0.1042 - val_accuracy: 0.9677\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9617 - val_loss: 0.1041 - val_accuracy: 0.9677\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9556 - val_loss: 0.1100 - val_accuracy: 0.9758\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9577 - val_loss: 0.1018 - val_accuracy: 0.9677\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9597 - val_loss: 0.0964 - val_accuracy: 0.9677\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9677 - val_loss: 0.1021 - val_accuracy: 0.9677\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9637 - val_loss: 0.0964 - val_accuracy: 0.9677\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9637 - val_loss: 0.0958 - val_accuracy: 0.9677\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9637 - val_loss: 0.0991 - val_accuracy: 0.9677\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9617 - val_loss: 0.1052 - val_accuracy: 0.9758\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9677 - val_loss: 0.0912 - val_accuracy: 0.9677\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9476 - val_loss: 0.1196 - val_accuracy: 0.9677\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9597 - val_loss: 0.0907 - val_accuracy: 0.9677\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9718 - val_loss: 0.0900 - val_accuracy: 0.9516\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9516 - val_loss: 0.1457 - val_accuracy: 0.9435\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9456 - val_loss: 0.0921 - val_accuracy: 0.9677\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9758 - val_loss: 0.1019 - val_accuracy: 0.9758\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9657 - val_loss: 0.1046 - val_accuracy: 0.9758\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9718 - val_loss: 0.0911 - val_accuracy: 0.9677\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9617 - val_loss: 0.0924 - val_accuracy: 0.9677\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9677 - val_loss: 0.0866 - val_accuracy: 0.9677\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9657 - val_loss: 0.0965 - val_accuracy: 0.9758\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9718 - val_loss: 0.0907 - val_accuracy: 0.9677\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9677 - val_loss: 0.0871 - val_accuracy: 0.9597\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9617 - val_loss: 0.1116 - val_accuracy: 0.9677\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9657 - val_loss: 0.0918 - val_accuracy: 0.9677\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9637 - val_loss: 0.0935 - val_accuracy: 0.9677\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9718 - val_loss: 0.0812 - val_accuracy: 0.9597\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9597 - val_loss: 0.1161 - val_accuracy: 0.9677\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9718 - val_loss: 0.0843 - val_accuracy: 0.9435\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9657 - val_loss: 0.0982 - val_accuracy: 0.9758\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 0.0876 - val_accuracy: 0.9677\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9778 - val_loss: 0.0851 - val_accuracy: 0.9677\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9698 - val_loss: 0.0916 - val_accuracy: 0.9758\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9657 - val_loss: 0.1030 - val_accuracy: 0.9758\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9738 - val_loss: 0.0808 - val_accuracy: 0.9516\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9637 - val_loss: 0.1143 - val_accuracy: 0.9677\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0964 - accuracy: 0.9677 - val_loss: 0.0901 - val_accuracy: 0.9758\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9738 - val_loss: 0.0866 - val_accuracy: 0.9677\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9738 - val_loss: 0.0794 - val_accuracy: 0.9677\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9657 - val_loss: 0.0829 - val_accuracy: 0.9677\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9617 - val_loss: 0.1049 - val_accuracy: 0.9758\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9738 - val_loss: 0.0869 - val_accuracy: 0.9677\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9738 - val_loss: 0.0809 - val_accuracy: 0.9677\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9698 - val_loss: 0.1253 - val_accuracy: 0.9597\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9597 - val_loss: 0.0800 - val_accuracy: 0.9597\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9597 - val_loss: 0.0812 - val_accuracy: 0.9597\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9677 - val_loss: 0.1031 - val_accuracy: 0.9677\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9718 - val_loss: 0.0863 - val_accuracy: 0.9597\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9476 - val_loss: 0.1164 - val_accuracy: 0.9677\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9698 - val_loss: 0.0805 - val_accuracy: 0.9677\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 0.0823 - val_accuracy: 0.9677\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 0.0977 - val_accuracy: 0.9758\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9798 - val_loss: 0.0823 - val_accuracy: 0.9677\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.0791 - val_accuracy: 0.9597\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9738 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9758 - val_loss: 0.0810 - val_accuracy: 0.9677\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9778 - val_loss: 0.0875 - val_accuracy: 0.9758\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9798 - val_loss: 0.0769 - val_accuracy: 0.9516\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9698 - val_loss: 0.0935 - val_accuracy: 0.9758\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.0870 - val_accuracy: 0.9758\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9798 - val_loss: 0.0901 - val_accuracy: 0.9758\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9778 - val_loss: 0.0815 - val_accuracy: 0.9677\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9487\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 3.7908 - accuracy: 0.4456 - val_loss: 2.4312 - val_accuracy: 0.4597\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3155 - accuracy: 0.5565 - val_loss: 0.7791 - val_accuracy: 0.5806\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.5685 - val_loss: 0.5980 - val_accuracy: 0.5887\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.6694 - val_loss: 0.5235 - val_accuracy: 0.7177\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7742 - val_loss: 0.5501 - val_accuracy: 0.7419\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7923 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8065 - val_loss: 0.4988 - val_accuracy: 0.7419\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8246 - val_loss: 0.4885 - val_accuracy: 0.7419\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8327 - val_loss: 0.4837 - val_accuracy: 0.7419\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8448 - val_loss: 0.4702 - val_accuracy: 0.7419\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8508 - val_loss: 0.4618 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8569 - val_loss: 0.4484 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8528 - val_loss: 0.4427 - val_accuracy: 0.7500\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8488 - val_loss: 0.4301 - val_accuracy: 0.7581\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8569 - val_loss: 0.4247 - val_accuracy: 0.7661\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8609 - val_loss: 0.4207 - val_accuracy: 0.7661\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8649 - val_loss: 0.4050 - val_accuracy: 0.7661\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8710 - val_loss: 0.3951 - val_accuracy: 0.7823\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.8710 - val_loss: 0.3953 - val_accuracy: 0.7903\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8851 - val_loss: 0.3785 - val_accuracy: 0.7984\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2859 - accuracy: 0.8972 - val_loss: 0.3738 - val_accuracy: 0.7984\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.9073 - val_loss: 0.3676 - val_accuracy: 0.8145\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.9173 - val_loss: 0.3583 - val_accuracy: 0.8306\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2629 - accuracy: 0.9173 - val_loss: 0.3530 - val_accuracy: 0.8226\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9153 - val_loss: 0.3404 - val_accuracy: 0.8387\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9194 - val_loss: 0.3327 - val_accuracy: 0.8226\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9294 - val_loss: 0.3243 - val_accuracy: 0.8306\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2357 - accuracy: 0.9194 - val_loss: 0.3203 - val_accuracy: 0.8306\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2264 - accuracy: 0.9294 - val_loss: 0.3064 - val_accuracy: 0.8548\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9254 - val_loss: 0.3086 - val_accuracy: 0.8387\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2152 - accuracy: 0.9194 - val_loss: 0.3006 - val_accuracy: 0.8629\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2118 - accuracy: 0.9335 - val_loss: 0.2993 - val_accuracy: 0.8387\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9274 - val_loss: 0.2901 - val_accuracy: 0.8629\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2020 - accuracy: 0.9294 - val_loss: 0.2860 - val_accuracy: 0.8710\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9435 - val_loss: 0.2824 - val_accuracy: 0.8548\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.9133 - val_loss: 0.2818 - val_accuracy: 0.8629\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1969 - accuracy: 0.9516 - val_loss: 0.2823 - val_accuracy: 0.8629\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9254 - val_loss: 0.2814 - val_accuracy: 0.8629\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9516 - val_loss: 0.2730 - val_accuracy: 0.8548\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9435 - val_loss: 0.2783 - val_accuracy: 0.8548\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9335 - val_loss: 0.2668 - val_accuracy: 0.8629\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1744 - accuracy: 0.9496 - val_loss: 0.2634 - val_accuracy: 0.8710\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9395 - val_loss: 0.2728 - val_accuracy: 0.8548\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9456 - val_loss: 0.2571 - val_accuracy: 0.8790\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1633 - accuracy: 0.9456 - val_loss: 0.2623 - val_accuracy: 0.8710\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9476 - val_loss: 0.2564 - val_accuracy: 0.8871\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9577 - val_loss: 0.2661 - val_accuracy: 0.8629\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9577 - val_loss: 0.2580 - val_accuracy: 0.8710\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9355 - val_loss: 0.2454 - val_accuracy: 0.8871\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9597 - val_loss: 0.2625 - val_accuracy: 0.8629\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9456 - val_loss: 0.2460 - val_accuracy: 0.8871\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.9637 - val_loss: 0.2479 - val_accuracy: 0.8790\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.9456 - val_loss: 0.2390 - val_accuracy: 0.8871\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9657 - val_loss: 0.2507 - val_accuracy: 0.8871\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9456 - val_loss: 0.2405 - val_accuracy: 0.8871\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9556 - val_loss: 0.2505 - val_accuracy: 0.8710\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1362 - accuracy: 0.9556 - val_loss: 0.2456 - val_accuracy: 0.8952\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9597 - val_loss: 0.2430 - val_accuracy: 0.8790\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9637 - val_loss: 0.2513 - val_accuracy: 0.8790\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9597 - val_loss: 0.2365 - val_accuracy: 0.8790\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9577 - val_loss: 0.2339 - val_accuracy: 0.8871\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9657 - val_loss: 0.2572 - val_accuracy: 0.8790\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9516 - val_loss: 0.2307 - val_accuracy: 0.8871\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9597 - val_loss: 0.2423 - val_accuracy: 0.8790\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9637 - val_loss: 0.2339 - val_accuracy: 0.8790\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.2392 - val_accuracy: 0.8790\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9698 - val_loss: 0.2605 - val_accuracy: 0.8871\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9536 - val_loss: 0.2267 - val_accuracy: 0.8790\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9698 - val_loss: 0.2560 - val_accuracy: 0.8871\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9556 - val_loss: 0.2302 - val_accuracy: 0.8790\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9657 - val_loss: 0.2367 - val_accuracy: 0.8871\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9677 - val_loss: 0.2273 - val_accuracy: 0.9032\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9617 - val_loss: 0.2372 - val_accuracy: 0.8790\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9657 - val_loss: 0.2327 - val_accuracy: 0.8871\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9677 - val_loss: 0.2308 - val_accuracy: 0.8871\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9657 - val_loss: 0.2269 - val_accuracy: 0.8790\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9617 - val_loss: 0.2355 - val_accuracy: 0.8952\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9698 - val_loss: 0.2323 - val_accuracy: 0.8871\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9657 - val_loss: 0.2453 - val_accuracy: 0.8871\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.2201 - val_accuracy: 0.8952\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9677 - val_loss: 0.2415 - val_accuracy: 0.8790\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9637 - val_loss: 0.2368 - val_accuracy: 0.8952\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9698 - val_loss: 0.2192 - val_accuracy: 0.9032\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9597 - val_loss: 0.2467 - val_accuracy: 0.8790\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 0.2148 - val_accuracy: 0.8952\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9657 - val_loss: 0.2351 - val_accuracy: 0.8790\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9698 - val_loss: 0.2197 - val_accuracy: 0.8952\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9637 - val_loss: 0.2267 - val_accuracy: 0.8790\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9657 - val_loss: 0.2091 - val_accuracy: 0.8871\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.9677 - val_loss: 0.2623 - val_accuracy: 0.8871\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9657 - val_loss: 0.2140 - val_accuracy: 0.8952\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9677 - val_loss: 0.2371 - val_accuracy: 0.8871\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9698 - val_loss: 0.2155 - val_accuracy: 0.8952\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9617 - val_loss: 0.2307 - val_accuracy: 0.8871\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9698 - val_loss: 0.2130 - val_accuracy: 0.8952\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9637 - val_loss: 0.2269 - val_accuracy: 0.8871\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9698 - val_loss: 0.2131 - val_accuracy: 0.8952\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9657 - val_loss: 0.2520 - val_accuracy: 0.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9617 - val_loss: 0.2064 - val_accuracy: 0.8871\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9637 - val_loss: 0.2196 - val_accuracy: 0.9032\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9698 - val_loss: 0.2256 - val_accuracy: 0.8871\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9657 - val_loss: 0.2091 - val_accuracy: 0.8952\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9698 - val_loss: 0.2303 - val_accuracy: 0.8952\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9698 - val_loss: 0.2214 - val_accuracy: 0.9032\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9677 - val_loss: 0.2155 - val_accuracy: 0.9032\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9657 - val_loss: 0.2342 - val_accuracy: 0.8871\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9657 - val_loss: 0.2146 - val_accuracy: 0.8952\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9698 - val_loss: 0.2332 - val_accuracy: 0.8952\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9677 - val_loss: 0.2069 - val_accuracy: 0.8871\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9577 - val_loss: 0.2254 - val_accuracy: 0.8952\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9677 - val_loss: 0.2155 - val_accuracy: 0.9032\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9657 - val_loss: 0.2269 - val_accuracy: 0.9032\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9637 - val_loss: 0.2408 - val_accuracy: 0.8871\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9637 - val_loss: 0.2102 - val_accuracy: 0.8952\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9677 - val_loss: 0.2417 - val_accuracy: 0.8952\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9637 - val_loss: 0.2069 - val_accuracy: 0.8871\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9657 - val_loss: 0.2335 - val_accuracy: 0.8952\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9677 - val_loss: 0.2134 - val_accuracy: 0.9032\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9637 - val_loss: 0.2247 - val_accuracy: 0.8952\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9677 - val_loss: 0.2129 - val_accuracy: 0.9113\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9657 - val_loss: 0.2180 - val_accuracy: 0.9113\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9637 - val_loss: 0.2264 - val_accuracy: 0.8952\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9657 - val_loss: 0.2238 - val_accuracy: 0.9032\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 0.2117 - val_accuracy: 0.8952\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9677 - val_loss: 0.2315 - val_accuracy: 0.9032\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9718 - val_loss: 0.2064 - val_accuracy: 0.9113\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9657 - val_loss: 0.2223 - val_accuracy: 0.9113\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9637 - val_loss: 0.2198 - val_accuracy: 0.9113\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9677 - val_loss: 0.2046 - val_accuracy: 0.9032\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9677 - val_loss: 0.2273 - val_accuracy: 0.9032\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9677 - val_loss: 0.2083 - val_accuracy: 0.9032\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9677 - val_loss: 0.2231 - val_accuracy: 0.9032\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9637 - val_loss: 0.2176 - val_accuracy: 0.8952\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9657 - val_loss: 0.2100 - val_accuracy: 0.9032\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9718 - val_loss: 0.2213 - val_accuracy: 0.9113\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9677 - val_loss: 0.2169 - val_accuracy: 0.9113\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9677 - val_loss: 0.2162 - val_accuracy: 0.9113\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9677 - val_loss: 0.2175 - val_accuracy: 0.9194\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9657 - val_loss: 0.2140 - val_accuracy: 0.9113\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9657 - val_loss: 0.2209 - val_accuracy: 0.9032\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9738 - val_loss: 0.2113 - val_accuracy: 0.9032\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9718 - val_loss: 0.2220 - val_accuracy: 0.9113\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9657 - val_loss: 0.2200 - val_accuracy: 0.9113\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9677 - val_loss: 0.2049 - val_accuracy: 0.8871\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.2429 - val_accuracy: 0.9032\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9677 - val_loss: 0.2079 - val_accuracy: 0.8871\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.2668 - val_accuracy: 0.8952\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9677 - val_loss: 0.1999 - val_accuracy: 0.8952\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9698 - val_loss: 0.2238 - val_accuracy: 0.9194\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9677 - val_loss: 0.2174 - val_accuracy: 0.9032\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9679\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 2.8135 - accuracy: 0.6069 - val_loss: 1.7453 - val_accuracy: 0.6290\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1657 - accuracy: 0.5766 - val_loss: 0.5934 - val_accuracy: 0.5806\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.6653 - val_loss: 0.6051 - val_accuracy: 0.6613\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7198 - val_loss: 0.5005 - val_accuracy: 0.7339\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7762 - val_loss: 0.4572 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7581 - val_loss: 0.4230 - val_accuracy: 0.7581\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.7903 - val_loss: 0.4092 - val_accuracy: 0.7742\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8105 - val_loss: 0.3918 - val_accuracy: 0.7903\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8206 - val_loss: 0.3802 - val_accuracy: 0.8226\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8206 - val_loss: 0.3693 - val_accuracy: 0.8065\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8286 - val_loss: 0.3616 - val_accuracy: 0.8306\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8387 - val_loss: 0.3482 - val_accuracy: 0.8387\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8448 - val_loss: 0.3379 - val_accuracy: 0.8387\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8669 - val_loss: 0.3284 - val_accuracy: 0.8790\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3118 - accuracy: 0.8730 - val_loss: 0.3207 - val_accuracy: 0.8387\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3028 - accuracy: 0.8871 - val_loss: 0.3104 - val_accuracy: 0.8710\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8891 - val_loss: 0.3043 - val_accuracy: 0.8790\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2841 - accuracy: 0.8952 - val_loss: 0.2925 - val_accuracy: 0.8871\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2768 - accuracy: 0.8972 - val_loss: 0.2845 - val_accuracy: 0.8952\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2682 - accuracy: 0.9052 - val_loss: 0.2738 - val_accuracy: 0.9032\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.9032 - val_loss: 0.2666 - val_accuracy: 0.9032\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9113 - val_loss: 0.2645 - val_accuracy: 0.8871\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.9032 - val_loss: 0.2532 - val_accuracy: 0.9032\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2412 - accuracy: 0.9133 - val_loss: 0.2442 - val_accuracy: 0.9194\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9113 - val_loss: 0.2410 - val_accuracy: 0.8952\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 0.9093 - val_loss: 0.2272 - val_accuracy: 0.9435\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2244 - accuracy: 0.9254 - val_loss: 0.2292 - val_accuracy: 0.9113\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9315 - val_loss: 0.2178 - val_accuracy: 0.9032\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9254 - val_loss: 0.2106 - val_accuracy: 0.9516\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9315 - val_loss: 0.2246 - val_accuracy: 0.8952\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9093 - val_loss: 0.2008 - val_accuracy: 0.9516\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2037 - accuracy: 0.9435 - val_loss: 0.2140 - val_accuracy: 0.8871\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1957 - accuracy: 0.9315 - val_loss: 0.1896 - val_accuracy: 0.9516\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9395 - val_loss: 0.1946 - val_accuracy: 0.9032\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1833 - accuracy: 0.9234 - val_loss: 0.1783 - val_accuracy: 0.9597\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9556 - val_loss: 0.1794 - val_accuracy: 0.9435\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1807 - accuracy: 0.9274 - val_loss: 0.1764 - val_accuracy: 0.9355\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9435 - val_loss: 0.1905 - val_accuracy: 0.8952\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1763 - accuracy: 0.9173 - val_loss: 0.1664 - val_accuracy: 0.9516\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9456 - val_loss: 0.1784 - val_accuracy: 0.9113\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.9536 - val_loss: 0.1607 - val_accuracy: 0.9274\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9516 - val_loss: 0.1589 - val_accuracy: 0.9355\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9516 - val_loss: 0.1568 - val_accuracy: 0.9355\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9496 - val_loss: 0.1547 - val_accuracy: 0.9355\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9476 - val_loss: 0.1485 - val_accuracy: 0.9597\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9617 - val_loss: 0.1572 - val_accuracy: 0.9355\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9435 - val_loss: 0.1471 - val_accuracy: 0.9355\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9556 - val_loss: 0.1632 - val_accuracy: 0.9194\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9476 - val_loss: 0.1417 - val_accuracy: 0.9355\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9677 - val_loss: 0.1461 - val_accuracy: 0.9355\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9577 - val_loss: 0.1392 - val_accuracy: 0.9355\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.9556 - val_loss: 0.1486 - val_accuracy: 0.9355\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9435 - val_loss: 0.1364 - val_accuracy: 0.9355\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9536 - val_loss: 0.1338 - val_accuracy: 0.9355\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9577 - val_loss: 0.1393 - val_accuracy: 0.9435\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1345 - accuracy: 0.9556 - val_loss: 0.1476 - val_accuracy: 0.9194\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9597 - val_loss: 0.1311 - val_accuracy: 0.9516\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9597 - val_loss: 0.1285 - val_accuracy: 0.9435\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9577 - val_loss: 0.1316 - val_accuracy: 0.9516\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9577 - val_loss: 0.1368 - val_accuracy: 0.9355\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9637 - val_loss: 0.1250 - val_accuracy: 0.9516\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.9597 - val_loss: 0.1321 - val_accuracy: 0.9355\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.9597 - val_loss: 0.1326 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9556 - val_loss: 0.1285 - val_accuracy: 0.9435\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1187 - accuracy: 0.9617 - val_loss: 0.1231 - val_accuracy: 0.9516\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9617 - val_loss: 0.1358 - val_accuracy: 0.9435\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9657 - val_loss: 0.1242 - val_accuracy: 0.9355\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9597 - val_loss: 0.1260 - val_accuracy: 0.9516\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9617 - val_loss: 0.1264 - val_accuracy: 0.9516\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9677 - val_loss: 0.1204 - val_accuracy: 0.9355\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9657 - val_loss: 0.1292 - val_accuracy: 0.9435\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9677 - val_loss: 0.1192 - val_accuracy: 0.9274\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.9657 - val_loss: 0.1243 - val_accuracy: 0.9516\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9637 - val_loss: 0.1238 - val_accuracy: 0.9435\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9657 - val_loss: 0.1293 - val_accuracy: 0.9355\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 0.1159 - val_accuracy: 0.9435\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9718 - val_loss: 0.1262 - val_accuracy: 0.9516\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9556 - val_loss: 0.1197 - val_accuracy: 0.9274\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9617 - val_loss: 0.1161 - val_accuracy: 0.9435\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9637 - val_loss: 0.1257 - val_accuracy: 0.9355\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9677 - val_loss: 0.1163 - val_accuracy: 0.9516\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9637 - val_loss: 0.1311 - val_accuracy: 0.9435\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9617 - val_loss: 0.1249 - val_accuracy: 0.9516\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9637 - val_loss: 0.1260 - val_accuracy: 0.9516\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9677 - val_loss: 0.1126 - val_accuracy: 0.9355\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9617 - val_loss: 0.1196 - val_accuracy: 0.9435\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9718 - val_loss: 0.1203 - val_accuracy: 0.9435\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9597 - val_loss: 0.1303 - val_accuracy: 0.9355\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9698 - val_loss: 0.1221 - val_accuracy: 0.9435\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.1187 - val_accuracy: 0.9355\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9597 - val_loss: 0.1144 - val_accuracy: 0.9355\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9657 - val_loss: 0.1189 - val_accuracy: 0.9435\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 0.1221 - val_accuracy: 0.9274\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9698 - val_loss: 0.1165 - val_accuracy: 0.9435\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 0.1425 - val_accuracy: 0.9435\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9677 - val_loss: 0.1177 - val_accuracy: 0.9435\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9677 - val_loss: 0.1245 - val_accuracy: 0.9355\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9698 - val_loss: 0.1368 - val_accuracy: 0.9435\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9677 - val_loss: 0.1194 - val_accuracy: 0.9435\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 0.1186 - val_accuracy: 0.9274\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9677 - val_loss: 0.1132 - val_accuracy: 0.9516\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9617 - val_loss: 0.1170 - val_accuracy: 0.9355\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9698 - val_loss: 0.1438 - val_accuracy: 0.9435\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9597 - val_loss: 0.1190 - val_accuracy: 0.9274\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9718 - val_loss: 0.1258 - val_accuracy: 0.9435\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9738 - val_loss: 0.1171 - val_accuracy: 0.9435\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9718 - val_loss: 0.1173 - val_accuracy: 0.9435\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9698 - val_loss: 0.1154 - val_accuracy: 0.9435\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9778 - val_loss: 0.1256 - val_accuracy: 0.9516\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9657 - val_loss: 0.1134 - val_accuracy: 0.9516\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9718 - val_loss: 0.1529 - val_accuracy: 0.9435\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 0.1250 - val_accuracy: 0.9435\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9597 - val_loss: 0.1377 - val_accuracy: 0.9435\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9758 - val_loss: 0.1123 - val_accuracy: 0.9597\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9738 - val_loss: 0.1228 - val_accuracy: 0.9435\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9738 - val_loss: 0.1139 - val_accuracy: 0.9516\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9718 - val_loss: 0.1566 - val_accuracy: 0.9274\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 0.1173 - val_accuracy: 0.9516\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.1257 - val_accuracy: 0.9435\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9718 - val_loss: 0.1314 - val_accuracy: 0.9516\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9677 - val_loss: 0.1157 - val_accuracy: 0.9274\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9758 - val_loss: 0.1309 - val_accuracy: 0.9435\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9677 - val_loss: 0.1173 - val_accuracy: 0.9516\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9637 - val_loss: 0.1316 - val_accuracy: 0.9355\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9677 - val_loss: 0.1505 - val_accuracy: 0.9355\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9577 - val_loss: 0.1185 - val_accuracy: 0.9516\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9556 - val_loss: 0.1760 - val_accuracy: 0.9274\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9577 - val_loss: 0.1147 - val_accuracy: 0.9516\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9657 - val_loss: 0.1311 - val_accuracy: 0.9435\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9657 - val_loss: 0.1268 - val_accuracy: 0.9435\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9738 - val_loss: 0.1268 - val_accuracy: 0.9435\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9657 - val_loss: 0.1228 - val_accuracy: 0.9274\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9758 - val_loss: 0.1311 - val_accuracy: 0.9355\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9698 - val_loss: 0.1250 - val_accuracy: 0.9435\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.1433 - val_accuracy: 0.9435\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9677 - val_loss: 0.1154 - val_accuracy: 0.9516\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.1683 - val_accuracy: 0.9274\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9516 - val_loss: 0.1229 - val_accuracy: 0.9516\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 0.1560 - val_accuracy: 0.9355\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.9698 - val_loss: 0.1220 - val_accuracy: 0.9435\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9738 - val_loss: 0.1166 - val_accuracy: 0.9355\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9778 - val_loss: 0.1337 - val_accuracy: 0.9435\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9718 - val_loss: 0.1221 - val_accuracy: 0.9435\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9758 - val_loss: 0.1379 - val_accuracy: 0.9435\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9698 - val_loss: 0.1216 - val_accuracy: 0.9597\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9778 - val_loss: 0.1354 - val_accuracy: 0.9355\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9698 - val_loss: 0.1181 - val_accuracy: 0.9516\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9677 - val_loss: 0.1569 - val_accuracy: 0.9355\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9738 - val_loss: 0.1188 - val_accuracy: 0.9516\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9738 - val_loss: 0.1494 - val_accuracy: 0.9435\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9295\n",
      "\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.6415 - accuracy: 0.4657 - val_loss: 0.8903 - val_accuracy: 0.4597\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8409 - accuracy: 0.4113 - val_loss: 0.7162 - val_accuracy: 0.4919\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.5726 - val_loss: 0.6036 - val_accuracy: 0.6452\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.6532 - val_loss: 0.5511 - val_accuracy: 0.6694\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7056 - val_loss: 0.5262 - val_accuracy: 0.6855\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7157 - val_loss: 0.5085 - val_accuracy: 0.6855\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7379 - val_loss: 0.4945 - val_accuracy: 0.6855\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7278 - val_loss: 0.4801 - val_accuracy: 0.6855\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7359 - val_loss: 0.4679 - val_accuracy: 0.6935\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7399 - val_loss: 0.4571 - val_accuracy: 0.7016\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7540 - val_loss: 0.4428 - val_accuracy: 0.7177\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7621 - val_loss: 0.4241 - val_accuracy: 0.7339\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.7722 - val_loss: 0.4166 - val_accuracy: 0.7661\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.7702 - val_loss: 0.4007 - val_accuracy: 0.7742\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.7944 - val_loss: 0.3943 - val_accuracy: 0.7984\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8145 - val_loss: 0.3805 - val_accuracy: 0.8226\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8327 - val_loss: 0.3734 - val_accuracy: 0.8548\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8407 - val_loss: 0.3632 - val_accuracy: 0.8710\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8569 - val_loss: 0.3578 - val_accuracy: 0.8790\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8669 - val_loss: 0.3462 - val_accuracy: 0.8710\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8790 - val_loss: 0.3427 - val_accuracy: 0.8710\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8810 - val_loss: 0.3312 - val_accuracy: 0.8710\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8810 - val_loss: 0.3294 - val_accuracy: 0.8548\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8810 - val_loss: 0.3159 - val_accuracy: 0.8629\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2998 - accuracy: 0.8931 - val_loss: 0.3151 - val_accuracy: 0.8548\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3033 - accuracy: 0.8790 - val_loss: 0.3018 - val_accuracy: 0.8629\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8790 - val_loss: 0.2973 - val_accuracy: 0.8629\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.9052 - val_loss: 0.3061 - val_accuracy: 0.8468\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8851 - val_loss: 0.2833 - val_accuracy: 0.8790\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.9073 - val_loss: 0.3020 - val_accuracy: 0.8468\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.8952 - val_loss: 0.2738 - val_accuracy: 0.8629\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9093 - val_loss: 0.2710 - val_accuracy: 0.8629\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9073 - val_loss: 0.2643 - val_accuracy: 0.8710\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9073 - val_loss: 0.2561 - val_accuracy: 0.8710\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9214 - val_loss: 0.2677 - val_accuracy: 0.8629\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9012 - val_loss: 0.2460 - val_accuracy: 0.8952\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9133 - val_loss: 0.2555 - val_accuracy: 0.8710\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2270 - accuracy: 0.9173 - val_loss: 0.2423 - val_accuracy: 0.8790\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9153 - val_loss: 0.2342 - val_accuracy: 0.9113\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.9133 - val_loss: 0.2906 - val_accuracy: 0.8548\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2342 - accuracy: 0.9113 - val_loss: 0.2279 - val_accuracy: 0.9032\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9315 - val_loss: 0.2678 - val_accuracy: 0.8710\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2157 - accuracy: 0.9153 - val_loss: 0.2232 - val_accuracy: 0.8952\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2070 - accuracy: 0.9335 - val_loss: 0.2431 - val_accuracy: 0.8790\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9294 - val_loss: 0.2197 - val_accuracy: 0.8790\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9214 - val_loss: 0.2182 - val_accuracy: 0.8790\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1975 - accuracy: 0.9435 - val_loss: 0.2158 - val_accuracy: 0.8952\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9335 - val_loss: 0.2158 - val_accuracy: 0.8952\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9355 - val_loss: 0.2146 - val_accuracy: 0.8952\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9375 - val_loss: 0.2284 - val_accuracy: 0.8871\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1901 - accuracy: 0.9274 - val_loss: 0.2001 - val_accuracy: 0.9113\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9335 - val_loss: 0.2579 - val_accuracy: 0.8710\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1890 - accuracy: 0.9214 - val_loss: 0.1953 - val_accuracy: 0.9194\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9435 - val_loss: 0.2165 - val_accuracy: 0.8871\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.9335 - val_loss: 0.1967 - val_accuracy: 0.9113\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9355 - val_loss: 0.1944 - val_accuracy: 0.9113\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9456 - val_loss: 0.1871 - val_accuracy: 0.9194\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 0.9395 - val_loss: 0.2040 - val_accuracy: 0.9032\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9496 - val_loss: 0.1855 - val_accuracy: 0.9113\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1662 - accuracy: 0.9516 - val_loss: 0.1896 - val_accuracy: 0.9113\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.9456 - val_loss: 0.1799 - val_accuracy: 0.9194\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9415 - val_loss: 0.1752 - val_accuracy: 0.9274\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9335 - val_loss: 0.1871 - val_accuracy: 0.9032\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.9577 - val_loss: 0.1764 - val_accuracy: 0.9194\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1557 - accuracy: 0.9496 - val_loss: 0.1801 - val_accuracy: 0.9194\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9516 - val_loss: 0.1762 - val_accuracy: 0.9194\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.9456 - val_loss: 0.1676 - val_accuracy: 0.9194\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9476 - val_loss: 0.1754 - val_accuracy: 0.9194\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9556 - val_loss: 0.1689 - val_accuracy: 0.9274\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9556 - val_loss: 0.1699 - val_accuracy: 0.9194\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1551 - accuracy: 0.9516 - val_loss: 0.1705 - val_accuracy: 0.9194\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1483 - accuracy: 0.9617 - val_loss: 0.1730 - val_accuracy: 0.9274\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9657 - val_loss: 0.1648 - val_accuracy: 0.9274\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9637 - val_loss: 0.1623 - val_accuracy: 0.9274\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9577 - val_loss: 0.1564 - val_accuracy: 0.9355\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9637 - val_loss: 0.1601 - val_accuracy: 0.9274\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9516 - val_loss: 0.1511 - val_accuracy: 0.9355\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9617 - val_loss: 0.1737 - val_accuracy: 0.9194\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9556 - val_loss: 0.1462 - val_accuracy: 0.9516\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9617 - val_loss: 0.1561 - val_accuracy: 0.9355\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9617 - val_loss: 0.1425 - val_accuracy: 0.9516\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.9677 - val_loss: 0.1531 - val_accuracy: 0.9355\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9698 - val_loss: 0.1409 - val_accuracy: 0.9435\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9698 - val_loss: 0.1574 - val_accuracy: 0.9194\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.9637 - val_loss: 0.1364 - val_accuracy: 0.9435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9657 - val_loss: 0.1601 - val_accuracy: 0.9274\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9637 - val_loss: 0.1317 - val_accuracy: 0.9516\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9677 - val_loss: 0.1400 - val_accuracy: 0.9516\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9758 - val_loss: 0.1330 - val_accuracy: 0.9435\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9698 - val_loss: 0.1319 - val_accuracy: 0.9435\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9577 - val_loss: 0.1254 - val_accuracy: 0.9516\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9657 - val_loss: 0.1338 - val_accuracy: 0.9435\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9718 - val_loss: 0.1385 - val_accuracy: 0.9435\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9617 - val_loss: 0.1229 - val_accuracy: 0.9355\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9637 - val_loss: 0.1607 - val_accuracy: 0.9113\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9556 - val_loss: 0.1192 - val_accuracy: 0.9516\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1162 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9435\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9758 - val_loss: 0.1177 - val_accuracy: 0.9516\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9798 - val_loss: 0.1455 - val_accuracy: 0.9194\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9758 - val_loss: 0.1149 - val_accuracy: 0.9516\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9819 - val_loss: 0.1244 - val_accuracy: 0.9516\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9677 - val_loss: 0.1131 - val_accuracy: 0.9516\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9698 - val_loss: 0.1219 - val_accuracy: 0.9516\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.9778 - val_loss: 0.1107 - val_accuracy: 0.9516\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9718 - val_loss: 0.1118 - val_accuracy: 0.9516\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9677 - val_loss: 0.1093 - val_accuracy: 0.9516\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9677 - val_loss: 0.1199 - val_accuracy: 0.9516\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.9698 - val_loss: 0.1085 - val_accuracy: 0.9516\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9758 - val_loss: 0.1122 - val_accuracy: 0.9435\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9758 - val_loss: 0.1113 - val_accuracy: 0.9435\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9718 - val_loss: 0.1250 - val_accuracy: 0.9435\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.9657 - val_loss: 0.1044 - val_accuracy: 0.9516\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9778 - val_loss: 0.1130 - val_accuracy: 0.9516\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9657 - val_loss: 0.1025 - val_accuracy: 0.9677\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9516 - val_loss: 0.1520 - val_accuracy: 0.9113\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9637 - val_loss: 0.1034 - val_accuracy: 0.9677\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9698 - val_loss: 0.1132 - val_accuracy: 0.9516\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9617 - val_loss: 0.1182 - val_accuracy: 0.9435\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9698 - val_loss: 0.0991 - val_accuracy: 0.9677\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9738 - val_loss: 0.1064 - val_accuracy: 0.9516\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9718 - val_loss: 0.1028 - val_accuracy: 0.9516\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9738 - val_loss: 0.0988 - val_accuracy: 0.9677\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9798 - val_loss: 0.1005 - val_accuracy: 0.9516\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9738 - val_loss: 0.0960 - val_accuracy: 0.9677\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9718 - val_loss: 0.0975 - val_accuracy: 0.9677\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 0.0998 - val_accuracy: 0.9516\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 0.0942 - val_accuracy: 0.9677\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9738 - val_loss: 0.1014 - val_accuracy: 0.9677\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9778 - val_loss: 0.0970 - val_accuracy: 0.9677\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9718 - val_loss: 0.0937 - val_accuracy: 0.9758\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9778 - val_loss: 0.1094 - val_accuracy: 0.9597\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9738 - val_loss: 0.0918 - val_accuracy: 0.9677\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9819 - val_loss: 0.1011 - val_accuracy: 0.9677\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9758 - val_loss: 0.0910 - val_accuracy: 0.9677\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9758 - val_loss: 0.0909 - val_accuracy: 0.9677\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9758 - val_loss: 0.0892 - val_accuracy: 0.9677\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9758 - val_loss: 0.0908 - val_accuracy: 0.9677\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9718 - val_loss: 0.1097 - val_accuracy: 0.9435\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 0.0890 - val_accuracy: 0.9677\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9738 - val_loss: 0.0933 - val_accuracy: 0.9677\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9758 - val_loss: 0.0871 - val_accuracy: 0.9677\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9738 - val_loss: 0.0931 - val_accuracy: 0.9597\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9718 - val_loss: 0.0895 - val_accuracy: 0.9677\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.0867 - val_accuracy: 0.9677\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 0.0864 - val_accuracy: 0.9677\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9758 - val_loss: 0.0858 - val_accuracy: 0.9677\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9778 - val_loss: 0.0890 - val_accuracy: 0.9677\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.0924 - val_accuracy: 0.9758\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 0.0852 - val_accuracy: 0.9677\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9677\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=np.zeros(10)\n",
    "precision=np.zeros(10)\n",
    "recall=np.zeros(10)\n",
    "for i in range(len(accuracy)):\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=10, activation='swish'))\n",
    "    model.add(Dense(40, activation='swish'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=50,validation_split=0.2)\n",
    "    # evaluate the keras model\n",
    "    results_nn = model.evaluate(X_test,y_test)\n",
    "    accuracy[i]=results_nn[1]\n",
    "    pred=np.zeros(len(y_test))\n",
    "    y_predict_r = model.predict(X_test)\n",
    "    for j in range(len(y_test)):\n",
    "        if y_predict_r[j]>=0.17:\n",
    "            pred[j]=int(1)\n",
    "        else:\n",
    "            pred[j]=int(0)\n",
    "    precision[i]=precision_score(y_test, pred)\n",
    "    recall[i]=recall_score(y_test,pred)\n",
    "    print()\n",
    "    #print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96153843 0.96153843 0.94230771 0.94230771 0.93589741 0.97435898\n",
      " 0.94871795 0.96794873 0.92948717 0.95512819] [0.92592593 0.93333333 0.88172043 0.94444444 0.83636364 0.99047619\n",
      " 0.92105263 0.88461538 0.94545455 0.92156863] [0.98039216 0.98989899 0.97619048 0.98076923 0.98924731 0.99047619\n",
      " 0.98130841 0.98924731 0.98113208 0.96907216]\n",
      "0.9519230723381042 0.9184955149750916 0.9827734319488652\n"
     ]
    }
   ],
   "source": [
    "print(accuracy,precision,recall)\n",
    "print(accuracy.mean(),precision.mean(),recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9565\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9808\n",
      "test loss, test acc: [0.08930135518312454, 0.9807692170143127]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)\n",
    "model.fit(X_train, y_train)\n",
    "results_nn = model.evaluate(X_test,y_test)\n",
    "print(\"test loss, test acc:\", results_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.982773</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.943396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Cross Val Accuracy  Accuracy  Cross val FRecall  Precision  \\\n",
       "0  Neural Network            0.951923  0.923077           0.982773   0.900901   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  0.990099  0.943396  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_predict_r = model.predict(X_test)\n",
    "#print(y_test)\n",
    "pred=np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    if y_predict_r[i]>=0.17:\n",
    "        pred[i]=int(1)\n",
    "    else:\n",
    "        pred[i]=int(0)\n",
    "#print(pred.astype(int))\n",
    "#print(pred)\n",
    "acc=accuracy_score(y_test,pred)\n",
    "roc=roc_auc_score(y_test, pred)\n",
    "prec = precision_score(y_test, pred)\n",
    "rec = recall_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "model_results = pd.DataFrame([['Neural Network', accuracy.mean(),acc,recall.mean(),prec,rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall',\"Precision\", 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussiaanNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Naive bayesian ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.89795918 0.97959184 0.89795918 0.91836735 0.71428571 0.63265306\n",
      " 0.83333333 0.72916667 0.79166667 0.3125    ] \n",
      " precision: [0.93617021 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ] \n",
      " accuracy: [0.8974359  0.98717949 0.93589744 0.94871795 0.82051282 0.76923077\n",
      " 0.8961039  0.83116883 0.87012987 0.57142857] \n",
      " fscore: [0.91666667 0.98969072 0.94623656 0.95744681 0.83333333 0.775\n",
      " 0.90909091 0.84337349 0.88372093 0.47619048] \n",
      "\n",
      "recall mean   : 0.7707482993197279 with starderd deviation: 0.18333181486251623\n",
      "precision mean: 0.9936170212765958 with starderd deviation: 0.01914893617021276\n",
      "accuracy mean : 0.8527805527805528 with starderd deviation: 0.11224761078080751\n",
      "fscore   mean : 0.8530749898789756 with starderd deviation: 0.13963479639027465\n"
     ]
    }
   ],
   "source": [
    "gaussian=GaussianNB()\n",
    "\n",
    "crs=cross_validate(gaussian, \n",
    "                     feature, \n",
    "                     target,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For Naive bayesian ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Cross Val Accuracy  Accuracy  Cross val FRecall    Recall  \\\n",
       "0   decision_tree            0.954839  0.967949           0.984480  1.000000   \n",
       "1             SVM            0.948387  0.929487           0.976923  0.989583   \n",
       "2  Neural Network            0.962821  0.961538           0.964960  0.940594   \n",
       "3      GaussianNB            0.852781  0.814103           0.770748  0.707071   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.975124  \n",
       "1  0.945274  \n",
       "2  0.969388  \n",
       "3  0.828402  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian.fit(X_train, y_train)\n",
    "y_predict_r = gaussian.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['GaussianNB', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Multinomial Naive bayesian ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.74358974 0.64102564 0.56410256 0.66666667 0.69230769 0.69230769\n",
      " 0.53846154 0.53846154 0.56410256 0.66666667] \n",
      " precision: [1.         1.         1.         1.         1.         1.\n",
      " 0.84       0.95454545 0.95652174 0.96296296] \n",
      " accuracy: [0.83870968 0.77419355 0.72580645 0.79032258 0.80645161 0.80645161\n",
      " 0.64516129 0.69354839 0.70967742 0.77419355] \n",
      " fscore: [0.85294118 0.78125    0.72131148 0.8        0.81818182 0.81818182\n",
      " 0.65625    0.68852459 0.70967742 0.78787879] \n",
      "\n",
      "recall mean   : 0.6307692307692307 with starderd deviation: 0.0699393933178762\n",
      "precision mean: 0.9714030156638854 with starderd deviation: 0.04769731842777352\n",
      "accuracy mean : 0.7564516129032258 with starderd deviation: 0.057456493969538294\n",
      "fscore   mean : 0.7634197085641622 with starderd deviation: 0.06166207605454081\n"
     ]
    }
   ],
   "source": [
    "multinomial=MultinomialNB()\n",
    "\n",
    "crs=cross_validate(multinomial, \n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For Multinomial Naive bayesian ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.977419</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.979032</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.979032</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.913793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.979032</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Cross Val Accuracy  Accuracy  Cross val FRecall  \\\n",
       "0            decision_tree            0.954839  0.967949           0.984480   \n",
       "1                      SVM            0.948387  0.929487           0.976923   \n",
       "2           Neural Network            0.962821  0.961538           0.964960   \n",
       "3               GaussianNB            0.852781  0.814103           0.770748   \n",
       "4            MultinomialNB            0.756452  0.737179           0.630769   \n",
       "5       LogisticRegression            0.953226  0.948718           0.976923   \n",
       "6   RandomForestClassifier            0.977419  0.974359           0.984480   \n",
       "7       AdaBoostClassifier            0.983871  0.993590           0.992308   \n",
       "8         GradientBoosting            0.979032  0.961538           0.984808   \n",
       "9            MultinomialNB            0.979032  0.711538           0.984808   \n",
       "10           MultinomialNB            0.979032  0.711538           0.984808   \n",
       "\n",
       "      Recall  F1 Score  Precision  \n",
       "0   1.000000  0.975124        NaN  \n",
       "1   0.989583  0.945274        NaN  \n",
       "2   0.940594  0.969388        NaN  \n",
       "3   0.707071  0.828402        NaN  \n",
       "4   0.614583  0.742138        NaN  \n",
       "5   0.947917  0.957895        NaN  \n",
       "6   1.000000  0.980392        NaN  \n",
       "7   0.989474  0.994709        NaN  \n",
       "8   0.978495  0.968085        NaN  \n",
       "9   0.569892  0.701987   0.913793  \n",
       "10  0.569892  0.701987        NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial.fit(X_train, y_train)\n",
    "y_predict_r = multinomial.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['MultinomialNB', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic regression ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [1.         1.         0.8974359  0.97435897 0.97435897 1.\n",
      " 1.         0.97435897 1.         0.94871795] \n",
      " precision: [0.95121951 0.92857143 0.97222222 0.97435897 0.97435897 0.975\n",
      " 0.95121951 0.95       0.95121951 0.88095238] \n",
      " accuracy: [0.96774194 0.9516129  0.91935484 0.96774194 0.96774194 0.98387097\n",
      " 0.96774194 0.9516129  0.96774194 0.88709677] \n",
      " fscore: [0.975      0.96296296 0.93333333 0.97435897 0.97435897 0.98734177\n",
      " 0.975      0.96202532 0.975      0.91358025] \n",
      "\n",
      "recall mean   : 0.976923076923077 with starderd deviation: 0.03129886055316334\n",
      "precision mean: 0.9509122517049347 with starderd deviation: 0.02743800902398217\n",
      "accuracy mean : 0.9532258064516128 with starderd deviation: 0.027419354838709695\n",
      "fscore   mean : 0.9632961580535421 with starderd deviation: 0.021459431163316754\n"
     ]
    }
   ],
   "source": [
    "logi = LogisticRegression(class_weight={1:1.6})\n",
    "crs=cross_validate(logi, \n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For Logistic regression ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Cross Val Accuracy  Accuracy  Cross val FRecall  \\\n",
       "0       decision_tree            0.954839  0.967949           0.984480   \n",
       "1                 SVM            0.948387  0.929487           0.976923   \n",
       "2      Neural Network            0.962821  0.961538           0.964960   \n",
       "3          GaussianNB            0.852781  0.814103           0.770748   \n",
       "4       MultinomialNB            0.756452  0.737179           0.630769   \n",
       "5  LogisticRegression            0.953226  0.948718           0.976923   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  1.000000  0.975124  \n",
       "1  0.989583  0.945274  \n",
       "2  0.940594  0.969388  \n",
       "3  0.707071  0.828402  \n",
       "4  0.614583  0.742138  \n",
       "5  0.947917  0.957895  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi.fit(X_train, y_train)\n",
    "y_predict_r = logi.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['LogisticRegression', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.94871795 0.94871795 1.         1.         1.         1.\n",
      " 1.         0.97368421 1.         0.97368421] \n",
      " precision: [1.         1.         0.92857143 0.975      0.975      0.975\n",
      " 1.         0.97368421 1.         0.97368421] \n",
      " accuracy: [0.96774194 0.96774194 0.9516129  0.98387097 0.98387097 0.98387097\n",
      " 1.         0.96774194 1.         0.96774194] \n",
      " fscore: [0.97368421 0.97368421 0.96296296 0.98734177 0.98734177 0.98734177\n",
      " 1.         0.97368421 1.         0.97368421] \n",
      "\n",
      "recall mean   : 0.9844804318488528 with starderd deviation: 0.020581956084530506\n",
      "precision mean: 0.980093984962406 with starderd deviation: 0.020975194923537388\n",
      "accuracy mean : 0.9774193548387096 with starderd deviation: 0.014782502241793019\n",
      "fscore   mean : 0.9819725121523921 with starderd deviation: 0.011715862028817185\n"
     ]
    }
   ],
   "source": [
    "random_forest_e = RandomForestClassifier(n_estimators = 100)\n",
    "crs=cross_validate(random_forest_e, \n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For Random Forest ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.977419</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Cross Val Accuracy  Accuracy  Cross val FRecall  \\\n",
       "0           decision_tree            0.954839  0.967949           0.984480   \n",
       "1                     SVM            0.948387  0.929487           0.976923   \n",
       "2          Neural Network            0.962821  0.961538           0.964960   \n",
       "3              GaussianNB            0.852781  0.814103           0.770748   \n",
       "4           MultinomialNB            0.756452  0.737179           0.630769   \n",
       "5      LogisticRegression            0.953226  0.948718           0.976923   \n",
       "6  RandomForestClassifier            0.977419  0.974359           0.984480   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  1.000000  0.975124  \n",
       "1  0.989583  0.945274  \n",
       "2  0.940594  0.969388  \n",
       "3  0.707071  0.828402  \n",
       "4  0.614583  0.742138  \n",
       "5  0.947917  0.957895  \n",
       "6  1.000000  0.980392  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_e.fit(X_train, y_train)\n",
    "y_predict_r = random_forest_e.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['RandomForestClassifier', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adaboost ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [1.         0.94871795 1.         1.         1.         0.97435897\n",
      " 1.         1.         1.         1.        ] \n",
      " precision: [1.         1.         1.         0.95121951 0.975      1.\n",
      " 1.         1.         0.90697674 1.        ] \n",
      " accuracy: [1.         0.96774194 1.         0.96774194 0.98387097 0.98387097\n",
      " 1.         1.         0.93548387 1.        ] \n",
      " fscore: [1.         0.97368421 1.         0.975      0.98734177 0.98701299\n",
      " 1.         1.         0.95121951 1.        ] \n",
      "\n",
      "recall mean   : 0.9923076923076923 with starderd deviation: 0.016418267275468856\n",
      "precision mean: 0.9833196256381168 with starderd deviation: 0.029791799583416257\n",
      "accuracy mean : 0.9838709677419354 with starderd deviation: 0.020401791355925035\n",
      "fscore   mean : 0.9874258481886324 with starderd deviation: 0.015636038714876625\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "crs=cross_validate(clf, \n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For adaboost ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.977419</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.994709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Cross Val Accuracy  Accuracy  Cross val FRecall  \\\n",
       "0           decision_tree            0.954839  0.967949           0.984480   \n",
       "1                     SVM            0.948387  0.929487           0.976923   \n",
       "2          Neural Network            0.962821  0.961538           0.964960   \n",
       "3              GaussianNB            0.852781  0.814103           0.770748   \n",
       "4           MultinomialNB            0.756452  0.737179           0.630769   \n",
       "5      LogisticRegression            0.953226  0.948718           0.976923   \n",
       "6  RandomForestClassifier            0.977419  0.974359           0.984480   \n",
       "7      AdaBoostClassifier            0.983871  0.993590           0.992308   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  1.000000  0.975124  \n",
       "1  0.989583  0.945274  \n",
       "2  0.940594  0.969388  \n",
       "3  0.707071  0.828402  \n",
       "4  0.614583  0.742138  \n",
       "5  0.947917  0.957895  \n",
       "6  1.000000  0.980392  \n",
       "7  0.989474  0.994709  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_predict_r = clf.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['AdaBoostClassifier', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(feature,\n",
    "                                               target,\n",
    "                                               test_size=0.2,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Gradient boosting ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [1.         0.975      0.95       0.97435897 0.97435897 0.97435897\n",
      " 1.         1.         1.         1.        ] \n",
      " precision: [1.         1.         0.97435897 0.95       0.97435897 0.97435897\n",
      " 1.         0.975      1.         0.975     ] \n",
      " accuracy: [1.         0.98387097 0.9516129  0.9516129  0.96774194 0.96774194\n",
      " 1.         0.98387097 1.         0.98387097] \n",
      " fscore: [1.         0.98734177 0.96202532 0.96202532 0.97435897 0.97435897\n",
      " 1.         0.98734177 1.         0.98734177] \n",
      "\n",
      "recall mean   : 0.9848076923076924 with starderd deviation: 0.016701270782768878\n",
      "precision mean: 0.9823076923076922 with starderd deviation: 0.016100338732394137\n",
      "accuracy mean : 0.9790322580645162 with starderd deviation: 0.01774193548387095\n",
      "fscore   mean : 0.9834793898085037 with starderd deviation: 0.013965901897826496\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "crs=cross_validate(clf, \n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     cv=10,\n",
    "                     scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                     n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"For Gradient boosting ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\")\n",
    "print(\"recall mean   :\", crs[\"test_recall\"].mean(),\"with starderd deviation:\",crs[\"test_recall\"].std())\n",
    "print(\"precision mean:\",crs[\"test_precision\"].mean(),\"with starderd deviation:\",crs[\"test_precision\"].std())\n",
    "print(\"accuracy mean :\",crs[\"test_accuracy\"].mean(),\"with starderd deviation:\",crs[\"test_accuracy\"].std())\n",
    "print(\"fscore   mean :\",crs[\"test_f1\"].mean(),\"with starderd deviation:\",crs[\"test_f1\"].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross Val Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross val FRecall</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.962821</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.969388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.852781</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.756452</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.977419</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.984480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.994709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.979032</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Cross Val Accuracy  Accuracy  Cross val FRecall  \\\n",
       "0           decision_tree            0.954839  0.967949           0.984480   \n",
       "1                     SVM            0.948387  0.929487           0.976923   \n",
       "2          Neural Network            0.962821  0.961538           0.964960   \n",
       "3              GaussianNB            0.852781  0.814103           0.770748   \n",
       "4           MultinomialNB            0.756452  0.737179           0.630769   \n",
       "5      LogisticRegression            0.953226  0.948718           0.976923   \n",
       "6  RandomForestClassifier            0.977419  0.974359           0.984480   \n",
       "7      AdaBoostClassifier            0.983871  0.993590           0.992308   \n",
       "8        GradientBoosting            0.979032  0.961538           0.984808   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  1.000000  0.975124  \n",
       "1  0.989583  0.945274  \n",
       "2  0.940594  0.969388  \n",
       "3  0.707071  0.828402  \n",
       "4  0.614583  0.742138  \n",
       "5  0.947917  0.957895  \n",
       "6  1.000000  0.980392  \n",
       "7  0.989474  0.994709  \n",
       "8  0.978495  0.968085  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_predict_r = clf.predict(X_test)\n",
    "roc=roc_auc_score(y_test, y_predict_r)\n",
    "acc = accuracy_score(list(y_test), list(y_predict_r))\n",
    "prec = precision_score(y_test, y_predict_r)\n",
    "rec = recall_score(y_test, y_predict_r)\n",
    "f1 = f1_score(y_test, y_predict_r)\n",
    "model_results = pd.DataFrame([['GradientBoosting', crs[\"test_accuracy\"].mean(),acc,crs[\"test_recall\"].mean(),rec, f1]],\n",
    "               columns = ['Model', 'Cross Val Accuracy','Accuracy', 'Cross val FRecall', 'Recall', 'F1 Score'])\n",
    "#results = results.append(model_results, ignore_index = True)\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Cross Val Accuracy</th>        <th class=\"col_heading level0 col2\" >Accuracy</th>        <th class=\"col_heading level0 col3\" >Cross val FRecall</th>        <th class=\"col_heading level0 col4\" >Recall</th>        <th class=\"col_heading level0 col5\" >F1 Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col0\" class=\"data row0 col0\" >decision_tree</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col1\" class=\"data row0 col1\" >0.954839</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col2\" class=\"data row0 col2\" >0.967949</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col3\" class=\"data row0 col3\" >0.984480</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row0_col5\" class=\"data row0 col5\" >0.975124</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col0\" class=\"data row1 col0\" >SVM</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col1\" class=\"data row1 col1\" >0.948387</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col2\" class=\"data row1 col2\" >0.929487</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col3\" class=\"data row1 col3\" >0.976923</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col4\" class=\"data row1 col4\" >0.989583</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row1_col5\" class=\"data row1 col5\" >0.945274</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col0\" class=\"data row2 col0\" >Neural Network</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col1\" class=\"data row2 col1\" >0.962821</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col2\" class=\"data row2 col2\" >0.961538</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col3\" class=\"data row2 col3\" >0.964960</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col4\" class=\"data row2 col4\" >0.940594</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row2_col5\" class=\"data row2 col5\" >0.969388</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col0\" class=\"data row3 col0\" >GaussianNB</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col1\" class=\"data row3 col1\" >0.852781</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col2\" class=\"data row3 col2\" >0.814103</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col3\" class=\"data row3 col3\" >0.770748</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col4\" class=\"data row3 col4\" >0.707071</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row3_col5\" class=\"data row3 col5\" >0.828402</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col0\" class=\"data row4 col0\" >MultinomialNB</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col1\" class=\"data row4 col1\" >0.756452</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col2\" class=\"data row4 col2\" >0.737179</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col3\" class=\"data row4 col3\" >0.630769</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col4\" class=\"data row4 col4\" >0.614583</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row4_col5\" class=\"data row4 col5\" >0.742138</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col0\" class=\"data row5 col0\" >LogisticRegression</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col1\" class=\"data row5 col1\" >0.953226</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col2\" class=\"data row5 col2\" >0.948718</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col3\" class=\"data row5 col3\" >0.976923</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col4\" class=\"data row5 col4\" >0.947917</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row5_col5\" class=\"data row5 col5\" >0.957895</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col0\" class=\"data row6 col0\" >RandomForestClassifier</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col1\" class=\"data row6 col1\" >0.977419</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col2\" class=\"data row6 col2\" >0.974359</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col3\" class=\"data row6 col3\" >0.984480</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col4\" class=\"data row6 col4\" >1.000000</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row6_col5\" class=\"data row6 col5\" >0.980392</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col0\" class=\"data row7 col0\" >AdaBoostClassifier</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col1\" class=\"data row7 col1\" >0.983871</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col2\" class=\"data row7 col2\" >0.993590</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col3\" class=\"data row7 col3\" >0.992308</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col4\" class=\"data row7 col4\" >0.989474</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row7_col5\" class=\"data row7 col5\" >0.994709</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col0\" class=\"data row8 col0\" >GradientBoosting</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col1\" class=\"data row8 col1\" >0.979032</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col2\" class=\"data row8 col2\" >0.961538</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col3\" class=\"data row8 col3\" >0.984808</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col4\" class=\"data row8 col4\" >0.978495</td>\n",
       "                        <td id=\"T_6f7a5690_4511_11eb_8daf_bb00069fb143row8_col5\" class=\"data row8 col5\" >0.968085</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4d4c431b50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
